{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "# Amateur Hour - Predicting Stocks using LightGBM\n### Starter Kernel by ``Magichanics`` \n*([GitHub](https://github.com/Magichanics) - [Kaggle](https://www.kaggle.com/magichanics))*\n\nThis is more of an improvement in organization and efficiency compared to my previous notebook. Feel free to post suggestions or criticisms!"
    },
    {
      "metadata": {
        "_uuid": "c6e9c58ee0984fd7aace750a5f542ceee09e17f0"
      },
      "cell_type": "markdown",
      "source": "## Table of Contents\n\n* [Step 1. Merging Datasets](#section1)\n* [Step 2. Feature Engineering](#section2)\n* [Step 3. Modelling using LightGBM](#section3)\n* [Step 4. Applying the Model](#section4)"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport os\nimport gc\nfrom itertools import chain\n\nimport matplotlib.pyplot as plt",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "85a94467c9c2550570e4e3bae4eb32f2bf6b95cd"
      },
      "cell_type": "code",
      "source": "import warnings\nwarnings.filterwarnings(\"ignore\")",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d9242e2e05ad6ae6897c99a33e224cc588621028",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "# import environment for data\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Loading the data... This could take a minute.\nDone!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "451e7c9bd35702323a7df4db34b91921254a1369"
      },
      "cell_type": "code",
      "source": "(market_train_df, news_train_df) = env.get_training_data()\nsampling = False\nif sampling:\n    market_train_df = market_train_df.tail(400_000)\n    news_train_df = news_train_df.tail(1_000_000)",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a58dabdb861587a6dc5d2917ecc742727f3d1e60"
      },
      "cell_type": "markdown",
      "source": "<a id='section1'></a>\n## Step 1. Merging Datasets\n\nWhile most of the notebooks focuses only on the market dataset, I'm going to attempt on bringing both the news and market dataset together."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98ddae667a406f38302133fe776106f15e873eca",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "market_train_df.head()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "                       time   ...    universe\n0 2007-02-01 22:00:00+00:00   ...         1.0\n1 2007-02-01 22:00:00+00:00   ...         0.0\n2 2007-02-01 22:00:00+00:00   ...         1.0\n3 2007-02-01 22:00:00+00:00   ...         1.0\n4 2007-02-01 22:00:00+00:00   ...         1.0\n\n[5 rows x 16 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>assetCode</th>\n      <th>assetName</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw1</th>\n      <th>returnsOpenPrevRaw1</th>\n      <th>returnsClosePrevMktres1</th>\n      <th>returnsOpenPrevMktres1</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n      <th>universe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2007-02-01 22:00:00+00:00</td>\n      <td>A.N</td>\n      <td>Agilent Technologies Inc</td>\n      <td>2606900.0</td>\n      <td>32.19</td>\n      <td>32.17</td>\n      <td>0.005938</td>\n      <td>0.005312</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.001860</td>\n      <td>0.000622</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.034672</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2007-02-01 22:00:00+00:00</td>\n      <td>AAI.N</td>\n      <td>AirTran Holdings Inc</td>\n      <td>2051600.0</td>\n      <td>11.12</td>\n      <td>11.08</td>\n      <td>0.004517</td>\n      <td>-0.007168</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.078708</td>\n      <td>-0.088066</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.027803</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2007-02-01 22:00:00+00:00</td>\n      <td>AAP.N</td>\n      <td>Advance Auto Parts Inc</td>\n      <td>1164800.0</td>\n      <td>37.51</td>\n      <td>37.99</td>\n      <td>-0.011594</td>\n      <td>0.025648</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.014332</td>\n      <td>0.045405</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.024433</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2007-02-01 22:00:00+00:00</td>\n      <td>AAPL.O</td>\n      <td>Apple Inc</td>\n      <td>23747329.0</td>\n      <td>84.74</td>\n      <td>86.23</td>\n      <td>-0.011548</td>\n      <td>0.016324</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.048613</td>\n      <td>-0.037182</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.007425</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2007-02-01 22:00:00+00:00</td>\n      <td>ABB.N</td>\n      <td>ABB Ltd</td>\n      <td>1208600.0</td>\n      <td>18.02</td>\n      <td>18.01</td>\n      <td>0.011791</td>\n      <td>0.025043</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.012929</td>\n      <td>0.020397</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.017994</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3573a5f315d0fad58e8102d3a80d1f8cb269f8b7"
      },
      "cell_type": "code",
      "source": "news_train_df.head()",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "                       time      ...       volumeCounts7D\n0 2007-01-01 04:29:32+00:00      ...                    7\n1 2007-01-01 07:03:35+00:00      ...                    3\n2 2007-01-01 11:29:56+00:00      ...                   17\n3 2007-01-01 12:08:37+00:00      ...                   15\n4 2007-01-01 12:08:37+00:00      ...                    0\n\n[5 rows x 35 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>sourceTimestamp</th>\n      <th>firstCreated</th>\n      <th>sourceId</th>\n      <th>headline</th>\n      <th>urgency</th>\n      <th>takeSequence</th>\n      <th>provider</th>\n      <th>subjects</th>\n      <th>audiences</th>\n      <th>bodySize</th>\n      <th>companyCount</th>\n      <th>headlineTag</th>\n      <th>marketCommentary</th>\n      <th>sentenceCount</th>\n      <th>wordCount</th>\n      <th>assetCodes</th>\n      <th>assetName</th>\n      <th>firstMentionSentence</th>\n      <th>relevance</th>\n      <th>sentimentClass</th>\n      <th>sentimentNegative</th>\n      <th>sentimentNeutral</th>\n      <th>sentimentPositive</th>\n      <th>sentimentWordCount</th>\n      <th>noveltyCount12H</th>\n      <th>noveltyCount24H</th>\n      <th>noveltyCount3D</th>\n      <th>noveltyCount5D</th>\n      <th>noveltyCount7D</th>\n      <th>volumeCounts12H</th>\n      <th>volumeCounts24H</th>\n      <th>volumeCounts3D</th>\n      <th>volumeCounts5D</th>\n      <th>volumeCounts7D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2007-01-01 04:29:32+00:00</td>\n      <td>2007-01-01 04:29:32+00:00</td>\n      <td>2007-01-01 04:29:32+00:00</td>\n      <td>e58c6279551b85cf</td>\n      <td>China's Daqing pumps 43.41 mln tonnes of oil i...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'ENR', 'ASIA', 'CN', 'NGS', 'EMRG', 'RTRS', '...</td>\n      <td>{'Z', 'O', 'OIL'}</td>\n      <td>1438</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>11</td>\n      <td>275</td>\n      <td>{'0857.HK', '0857.F', '0857.DE', 'PTR.N'}</td>\n      <td>PetroChina Co Ltd</td>\n      <td>6</td>\n      <td>0.235702</td>\n      <td>-1</td>\n      <td>0.500739</td>\n      <td>0.419327</td>\n      <td>0.079934</td>\n      <td>73</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>6</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2007-01-01 07:03:35+00:00</td>\n      <td>2007-01-01 07:03:34+00:00</td>\n      <td>2007-01-01 07:03:34+00:00</td>\n      <td>5a31c4327427f63f</td>\n      <td>FEATURE-In kidnapping, finesse works best</td>\n      <td>3</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'FEA', 'CA', 'LATAM', 'MX', 'INS', 'ASIA', 'I...</td>\n      <td>{'PGE', 'PCO', 'G', 'ESN', 'MD', 'PCU', 'DNP',...</td>\n      <td>4413</td>\n      <td>1</td>\n      <td>FEATURE</td>\n      <td>False</td>\n      <td>55</td>\n      <td>907</td>\n      <td>{'STA.N'}</td>\n      <td>Travelers Companies Inc</td>\n      <td>8</td>\n      <td>0.447214</td>\n      <td>-1</td>\n      <td>0.600082</td>\n      <td>0.345853</td>\n      <td>0.054064</td>\n      <td>62</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2007-01-01 11:29:56+00:00</td>\n      <td>2007-01-01 11:29:56+00:00</td>\n      <td>2007-01-01 11:29:56+00:00</td>\n      <td>1cefd27a40fabdfe</td>\n      <td>PRESS DIGEST - Wall Street Journal - Jan 1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'RET', 'ENR', 'ID', 'BG', 'US', 'PRESS', 'IQ'...</td>\n      <td>{'T', 'DNP', 'PSC', 'U', 'D', 'M', 'RNP', 'PTD...</td>\n      <td>2108</td>\n      <td>2</td>\n      <td>PRESS DIGEST</td>\n      <td>False</td>\n      <td>15</td>\n      <td>388</td>\n      <td>{'WMT.DE', 'WMT.N'}</td>\n      <td>Wal-Mart Stores Inc</td>\n      <td>14</td>\n      <td>0.377964</td>\n      <td>-1</td>\n      <td>0.450049</td>\n      <td>0.295671</td>\n      <td>0.254280</td>\n      <td>67</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>11</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2007-01-01 12:08:37+00:00</td>\n      <td>2007-01-01 12:08:37+00:00</td>\n      <td>2007-01-01 12:08:37+00:00</td>\n      <td>23768af19dc69992</td>\n      <td>PRESS DIGEST - New York Times - Jan 1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'FUND', 'FIN', 'CA', 'SFWR', 'INS', 'PUB', 'B...</td>\n      <td>{'T', 'DNP', 'PSC', 'U', 'D', 'M', 'RNP', 'PTD...</td>\n      <td>1776</td>\n      <td>6</td>\n      <td>PRESS DIGEST</td>\n      <td>False</td>\n      <td>14</td>\n      <td>325</td>\n      <td>{'GOOG.O', 'GOOG.OQ', 'GOOGa.DE'}</td>\n      <td>Google Inc</td>\n      <td>13</td>\n      <td>0.149071</td>\n      <td>-1</td>\n      <td>0.752917</td>\n      <td>0.162715</td>\n      <td>0.084368</td>\n      <td>83</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>13</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2007-01-01 12:08:37+00:00</td>\n      <td>2007-01-01 12:08:37+00:00</td>\n      <td>2007-01-01 12:08:37+00:00</td>\n      <td>23768af19dc69992</td>\n      <td>PRESS DIGEST - New York Times - Jan 1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'FUND', 'FIN', 'CA', 'SFWR', 'INS', 'PUB', 'B...</td>\n      <td>{'T', 'DNP', 'PSC', 'U', 'D', 'M', 'RNP', 'PTD...</td>\n      <td>1776</td>\n      <td>6</td>\n      <td>PRESS DIGEST</td>\n      <td>False</td>\n      <td>14</td>\n      <td>325</td>\n      <td>{'XMSR.O'}</td>\n      <td>XM Satellite Radio Holdings Inc</td>\n      <td>11</td>\n      <td>0.149071</td>\n      <td>-1</td>\n      <td>0.699274</td>\n      <td>0.209360</td>\n      <td>0.091366</td>\n      <td>102</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c35fe1a86234868804664c40675a7a4468b48d70"
      },
      "cell_type": "code",
      "source": "from datetime import datetime, timedelta\nstart = datetime(2015, 1, 1, 0, 0, 0).date()\nmarket_train_df = market_train_df.loc[market_train_df['time'].dt.date >= start].reset_index(drop=True)\nnews_train_df = news_train_df.loc[news_train_df['time'].dt.date >= start].reset_index(drop=True)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "13f7b88ce7c3473340251903b17106af89e8e213"
      },
      "cell_type": "markdown",
      "source": "### Cleaning Data\nWe will be removing the rows with the following qualities, as well as features that have almost no correlation with the given data:\n* Empty headlines\n* Repeat headlines\n* Urgency of 2"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b2a9a6a69a66557f69b30b5e27553a2ba15bc933"
      },
      "cell_type": "code",
      "source": "def clean_data(market_df, news_df, train=True):\n    \n    # get rid of invalid rows\n    news_df = news_df[news_df.headline != '']\n    news_df = news_df[news_df.urgency != 2]\n    \n    # remove duplicate headlines with the same assetCodes\n    news_df = news_df.drop_duplicates(subset=['assetCodes', 'headline'],keep='first')\n    \n    # keep only the following features\n#     news_df = news_df[['time', 'assetCodes', 'headline', 'subjects', 'audiences']]\n    news_df = news_df[['time', 'assetCodes', 'headline']]\n    valid_market_cols = ['time', 'assetCode', 'volume', 'close', 'open',\\\n                           'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\\\n                           'returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\n    if train:\n        valid_market_cols += ['returnsOpenNextMktres10']\n    market_df = market_df[valid_market_cols]\n\n    return market_df, news_df",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5e814659d584d93fa399c07746d050ba5ca62b2e"
      },
      "cell_type": "code",
      "source": "market_train_df, news_train_df = clean_data(market_train_df, news_train_df, train=True)",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "54ea9c0ee8287b5edc984a84c07030a0e106d6c8"
      },
      "cell_type": "code",
      "source": "news_train_df.shape",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "(1773344, 3)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b4b177c09e0546499a260041b7fb604673813ccf"
      },
      "cell_type": "code",
      "source": "market_train_df.shape",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "(892200, 10)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "486d593869589819aefadb4345af1b5db0060ffc"
      },
      "cell_type": "markdown",
      "source": "### Expanding News data\nWe are going to be splitting the news data by assetCode."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "29b5aa276e3bfb61ae5a83dbb24162da1f0a72c6"
      },
      "cell_type": "code",
      "source": "def expanding_news(news_df):\n    \n    # split to list\n    news_output = news_df.copy()\n    news_output['assetCodes'] = news_output['assetCodes'].str.findall(f\"'([\\w\\./]+)'\")\n    \n    # separate to assetcodes\n    assetCodes_expanded = list(chain(*news_output['assetCodes']))\n    assetCodes_index = news_df.index.repeat(news_output['assetCodes'].apply(len))\n    assert len(assetCodes_index) == len(assetCodes_expanded)\n    df_assetCodes = pd.DataFrame({'level_0': assetCodes_index, 'assetCode': assetCodes_expanded})\n    \n    # merge to dataframe\n    merging_cols = [f for f in news_output if f not in ['assetCodes', 'sourceId']]\n    news_df_expanded = pd.merge(df_assetCodes, news_output[merging_cols], left_on='level_0', \n                                right_index=True, suffixes=(['','_old']))\n    \n    return news_df_expanded",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "783cae5ad82f345e1d620fcdf7b22e9c76fa3e29"
      },
      "cell_type": "code",
      "source": "expand_train_df = expanding_news(news_train_df)",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "368a6fd592fc50eeefa583123cb1b1fa7ad28dd3"
      },
      "cell_type": "code",
      "source": "expand_train_df.tail()",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "         level_0                        ...                                                                   headline\n3243658  2054221                        ...                          EQUITY ALERT: Rosen Law Firm Announces Investi...\n3243659  2054221                        ...                          EQUITY ALERT: Rosen Law Firm Announces Investi...\n3243660  2054222                        ...                          PROFESSIONAL DIVERSITY NETWORK INC - FILES FOR...\n3243661  2054222                        ...                          PROFESSIONAL DIVERSITY NETWORK INC - FILES FOR...\n3243662  2054223                        ...                          JPMorgan China Region Fund, Inc. Board to Subm...\n\n[5 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>assetCode</th>\n      <th>time</th>\n      <th>headline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3243658</th>\n      <td>2054221</td>\n      <td>SGEN.O</td>\n      <td>2016-12-30 21:57:00+00:00</td>\n      <td>EQUITY ALERT: Rosen Law Firm Announces Investi...</td>\n    </tr>\n    <tr>\n      <th>3243659</th>\n      <td>2054221</td>\n      <td>SGEN.OQ</td>\n      <td>2016-12-30 21:57:00+00:00</td>\n      <td>EQUITY ALERT: Rosen Law Firm Announces Investi...</td>\n    </tr>\n    <tr>\n      <th>3243660</th>\n      <td>2054222</td>\n      <td>IPDN.O</td>\n      <td>2016-12-30 21:58:53+00:00</td>\n      <td>PROFESSIONAL DIVERSITY NETWORK INC - FILES FOR...</td>\n    </tr>\n    <tr>\n      <th>3243661</th>\n      <td>2054222</td>\n      <td>IPDN.OQ</td>\n      <td>2016-12-30 21:58:53+00:00</td>\n      <td>PROFESSIONAL DIVERSITY NETWORK INC - FILES FOR...</td>\n    </tr>\n    <tr>\n      <th>3243662</th>\n      <td>2054223</td>\n      <td>JFC.N</td>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>JPMorgan China Region Fund, Inc. Board to Subm...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3e4b182a9fd045db6a0ef4941324471ef60496f6"
      },
      "cell_type": "code",
      "source": "market_train_df.tail()",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "                            time           ...           returnsOpenNextMktres10\n892195 2016-12-30 22:00:00+00:00           ...                          0.051189\n892196 2016-12-30 22:00:00+00:00           ...                         -0.048555\n892197 2016-12-30 22:00:00+00:00           ...                          0.011703\n892198 2016-12-30 22:00:00+00:00           ...                          0.083367\n892199 2016-12-30 22:00:00+00:00           ...                         -0.016220\n\n[5 rows x 10 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>assetCode</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>892195</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZIOP.O</td>\n      <td>1608829.0</td>\n      <td>5.35</td>\n      <td>5.37</td>\n      <td>-0.165367</td>\n      <td>-0.138042</td>\n      <td>-0.139597</td>\n      <td>-0.135913</td>\n      <td>0.051189</td>\n    </tr>\n    <tr>\n      <th>892196</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZLTQ.O</td>\n      <td>347830.0</td>\n      <td>43.52</td>\n      <td>43.62</td>\n      <td>0.002996</td>\n      <td>0.002989</td>\n      <td>0.008213</td>\n      <td>0.003210</td>\n      <td>-0.048555</td>\n    </tr>\n    <tr>\n      <th>892197</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZNGA.O</td>\n      <td>7396601.0</td>\n      <td>2.57</td>\n      <td>2.58</td>\n      <td>-0.091873</td>\n      <td>-0.078571</td>\n      <td>-0.077252</td>\n      <td>-0.077188</td>\n      <td>0.011703</td>\n    </tr>\n    <tr>\n      <th>892198</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZTO.N</td>\n      <td>3146519.0</td>\n      <td>12.07</td>\n      <td>12.50</td>\n      <td>-0.065066</td>\n      <td>-0.042146</td>\n      <td>-0.078104</td>\n      <td>-0.043813</td>\n      <td>0.083367</td>\n    </tr>\n    <tr>\n      <th>892199</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZTS.N</td>\n      <td>1701204.0</td>\n      <td>53.53</td>\n      <td>53.64</td>\n      <td>0.023127</td>\n      <td>0.028177</td>\n      <td>0.026566</td>\n      <td>0.028719</td>\n      <td>-0.016220</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "e2c2e63e365f4b89f660f17ffbeb38545a0c05db"
      },
      "cell_type": "markdown",
      "source": "### Cleaning Headlines\nThe following will simplify strings to only get the necessary words needed for text processing."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e8e89a5e3cfd230ee137cf88be5f557765243d5e"
      },
      "cell_type": "code",
      "source": "from nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport re\n\nps = PorterStemmer()\nsw = stopwords.words('english')\n\n# this takes up a lot of time, so apply it when getting coefficients to filter out words.\ndef clean_headlines(headline):\n    \n    # remove numerical and convert to lowercase\n    headline =  re.sub('[^a-zA-Z]',' ',headline)\n    headline = headline.lower()\n    \n    # use stemming to simplify words\n    headline_words_rough = headline.split(' ')\n    \n    # check if stopwords are present in headlines\n    headline_words = []\n    for word in headline_words_rough:\n        if word not in sw:\n            # use stemming to simplify\n            headline_words.append(ps.stem(word))\n    \n    # join sentence back again\n    return ' '.join(headline_words)",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c90a1d3d5da39a17a36b06a756470ff6dee6d53b"
      },
      "cell_type": "markdown",
      "source": "### Categorical Groupby\nThis will merge groups of categorical data together into either lists or sets."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "27a4e721de05191399c01e8724a39022d0f1b77e"
      },
      "cell_type": "code",
      "source": "def categorical_groupby(expand_df):\n\n    # get categorical groupbys\n    main_cols = ['time', 'assetCode']\n    expand_headline_groupby = expand_df[main_cols + ['headline']].groupby(['time', 'assetCode'])\n    #expand_cat_groupby = expand_df[main_cols + ['subjects', 'audiences']].groupby(['time', 'assetCode'])\n    \n    # split subjects and audiences\n    def cat_to_list(x):\n        try:\n            if x.name not in ['time', 'assetCode'] and x.name != 'headline':\n                result = []\n                for item in x:\n                    result += item\n                return list(set(result)) # returns unique audiences/subjects\n            elif x.name == 'headline':\n                return list(x)\n        except ValueError:\n            return np.nan\n    \n    # convert groupby to dataframes\n#     expand_cat_df = expand_cat_groupby.transform(lambda x: cat_to_list(x))\n    expand_headline_df = expand_headline_groupby.transform(lambda x: cat_to_list(x)) # can't iterate through?\n\n    # merge to categorical dataframes\n#     return pd.concat([expand_cat_df, expand_headline_df], axis=1)\n    return expand_headline_df\n    ",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5538d778f93b8193ec36ef8c11d6ac0ea3f305a0"
      },
      "cell_type": "markdown",
      "source": "### Merge by time &  assetCode to News Article\nWe will be merging rows with the same time and assetCode."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1653c7e20b8d9bcd4541c2f7da29549d3b1f7f2b"
      },
      "cell_type": "code",
      "source": "def get_matches(market_df, expand_df):\n    \n    # get temporary columns as data\n    temp_market_df = market_df[['time', 'assetCode']].copy()\n    temp_expand_df = expand_df[['time', 'assetCode']].copy()\n    \n    # get indecies\n    temp_expand_df['expand_index'] = temp_expand_df.index.values\n    \n    # join the two\n    temp_expand_df.set_index(['time', 'assetCode'], inplace=True)\n    temp_expand_market_df = temp_market_df.join(temp_expand_df, on=['time', 'assetCode'])\n    \n    # remove nulls\n    temp_expand_market_df = temp_expand_market_df[temp_expand_market_df.expand_index.isnull() == False]\n    expand_indicies = temp_expand_market_df['expand_index'].tolist()\n    \n    # do final cleanup\n    del temp_market_df\n    del temp_expand_df\n    \n    # fetch matches\n    return expand_df.loc[expand_indicies]\n\ndef merge_by_code(market_df, expand_df):\n    \n    # use a copy\n    market_df_copy = market_df.copy()\n    \n    # get expansion of rows\n    expand_df = get_matches(market_df, expand_df)\n    \n    # check if empty\n    if len(expand_df) == 0:\n        \n#         news_cols = ['subjects', 'audiences', 'headline']\n        news_cols = ['headline']\n        \n        # create blank columns of what was supposed to be there\n        for f in news_cols:\n            market_df_copy[f] = np.nan\n        \n        return market_df_copy\n    \n#     # convert to lists\n#     expand_df['subjects'] = expand_df['subjects'].str.findall(f\"'([\\w\\./]+)'\")\n#     expand_df['audiences'] = expand_df['audiences'].str.findall(f\"'([\\w\\./]+)'\")\n    \n    # clean headlines\n    expand_df['headline'] = expand_df['headline'].apply(clean_headlines)\n    \n    # group categoricals\n    expand_cat_df = categorical_groupby(expand_df)\n    expand_cat_df['time'] = expand_df['time']\n    expand_cat_df['assetCode'] = expand_df['assetCode']\n    \n#     # convert to sets\n#     for cat_col in ['subjects', 'audiences']:\n#         expand_cat_df[cat_col] = expand_cat_df[cat_col].apply(tuple)\n        \n    # remove duplicate rows\n    expand_cat_df = expand_cat_df.drop_duplicates(subset=['time', 'assetCode'],\n                                                  keep='first')\n    \n    # merge datasets\n    expanded_market_df = pd.merge(market_df_copy, expand_cat_df, \n                                  on=['time', 'assetCode'], how='left')\n    \n    return expanded_market_df\n    ",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9d57e35717560cdafdc3101450cf48d793492ab9"
      },
      "cell_type": "code",
      "source": "%%time\nX_train = merge_by_code(market_train_df, expand_train_df)",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "CPU times: user 3.88 s, sys: 1.32 s, total: 5.2 s\nWall time: 5.2 s\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eff9fd44d08967c5719fc2151dc77e2c945aac00"
      },
      "cell_type": "code",
      "source": "X_train.tail()",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "                            time   ...    headline\n892195 2016-12-30 22:00:00+00:00   ...         NaN\n892196 2016-12-30 22:00:00+00:00   ...         NaN\n892197 2016-12-30 22:00:00+00:00   ...         NaN\n892198 2016-12-30 22:00:00+00:00   ...         NaN\n892199 2016-12-30 22:00:00+00:00   ...         NaN\n\n[5 rows x 11 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>assetCode</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n      <th>headline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>892195</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZIOP.O</td>\n      <td>1608829.0</td>\n      <td>5.35</td>\n      <td>5.37</td>\n      <td>-0.165367</td>\n      <td>-0.138042</td>\n      <td>-0.139597</td>\n      <td>-0.135913</td>\n      <td>0.051189</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>892196</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZLTQ.O</td>\n      <td>347830.0</td>\n      <td>43.52</td>\n      <td>43.62</td>\n      <td>0.002996</td>\n      <td>0.002989</td>\n      <td>0.008213</td>\n      <td>0.003210</td>\n      <td>-0.048555</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>892197</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZNGA.O</td>\n      <td>7396601.0</td>\n      <td>2.57</td>\n      <td>2.58</td>\n      <td>-0.091873</td>\n      <td>-0.078571</td>\n      <td>-0.077252</td>\n      <td>-0.077188</td>\n      <td>0.011703</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>892198</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZTO.N</td>\n      <td>3146519.0</td>\n      <td>12.07</td>\n      <td>12.50</td>\n      <td>-0.065066</td>\n      <td>-0.042146</td>\n      <td>-0.078104</td>\n      <td>-0.043813</td>\n      <td>0.083367</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>892199</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZTS.N</td>\n      <td>1701204.0</td>\n      <td>53.53</td>\n      <td>53.64</td>\n      <td>0.023127</td>\n      <td>0.028177</td>\n      <td>0.026566</td>\n      <td>0.028719</td>\n      <td>-0.016220</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c6e0cb4a4a1afdf47dd0501b41b62107d2fa7fe4"
      },
      "cell_type": "code",
      "source": "def data_step1(market_test_df, news_test_df):\n    \n    market_test_df, news_test_df = clean_data(market_test_df, news_test_df, train=False)\n    expand_test_df = expanding_news(news_test_df)\n    X_test = merge_by_code(market_test_df, expand_test_df)\n    del market_test_df, news_test_df, expand_test_df\n    gc.collect()\n    \n    return X_test\n    ",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "91780d18359c8faf6cf6e224995aa882926754db"
      },
      "cell_type": "code",
      "source": "del market_train_df, news_train_df, expand_train_df\ngc.collect()",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "96"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "b24a1eb7424ef10af9dbb4ee7c177dfefa220f51"
      },
      "cell_type": "markdown",
      "source": "<a id='section2'></a>\n## Step 2. Feature Engineering\n\nFrom Quant features to text processing features."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "434e633c799d075f6dcc14e6d00104b5cafbe0b4"
      },
      "cell_type": "code",
      "source": "X_train.tail()",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "                            time   ...    headline\n892195 2016-12-30 22:00:00+00:00   ...         NaN\n892196 2016-12-30 22:00:00+00:00   ...         NaN\n892197 2016-12-30 22:00:00+00:00   ...         NaN\n892198 2016-12-30 22:00:00+00:00   ...         NaN\n892199 2016-12-30 22:00:00+00:00   ...         NaN\n\n[5 rows x 11 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>assetCode</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n      <th>headline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>892195</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZIOP.O</td>\n      <td>1608829.0</td>\n      <td>5.35</td>\n      <td>5.37</td>\n      <td>-0.165367</td>\n      <td>-0.138042</td>\n      <td>-0.139597</td>\n      <td>-0.135913</td>\n      <td>0.051189</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>892196</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZLTQ.O</td>\n      <td>347830.0</td>\n      <td>43.52</td>\n      <td>43.62</td>\n      <td>0.002996</td>\n      <td>0.002989</td>\n      <td>0.008213</td>\n      <td>0.003210</td>\n      <td>-0.048555</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>892197</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZNGA.O</td>\n      <td>7396601.0</td>\n      <td>2.57</td>\n      <td>2.58</td>\n      <td>-0.091873</td>\n      <td>-0.078571</td>\n      <td>-0.077252</td>\n      <td>-0.077188</td>\n      <td>0.011703</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>892198</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZTO.N</td>\n      <td>3146519.0</td>\n      <td>12.07</td>\n      <td>12.50</td>\n      <td>-0.065066</td>\n      <td>-0.042146</td>\n      <td>-0.078104</td>\n      <td>-0.043813</td>\n      <td>0.083367</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>892199</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZTS.N</td>\n      <td>1701204.0</td>\n      <td>53.53</td>\n      <td>53.64</td>\n      <td>0.023127</td>\n      <td>0.028177</td>\n      <td>0.026566</td>\n      <td>0.028719</td>\n      <td>-0.016220</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "26fb740a713963d533d1cb9684b81a3f6795525a"
      },
      "cell_type": "markdown",
      "source": "### Text Processing with CountVectorizer\nWe are going to be using CountVectorizer on headlines, audiences and subjects to determine its influence on the target column."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "47ec4db7796b018c4991b5220a4bfeee5c4885d7",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\n\nclass TextToCoeff:\n\n    def vectorize(self, X_):\n\n        # get required dataset\n        X_text = X_.copy()[['returnsOpenNextMktres10', self.col]].dropna()\n\n        # round data (if objective : binary)\n        def round_scores(x):\n            if x >= 0:\n                return 1\n            else:\n                return 0\n        X_text['returnsOpenNextMktres10'] = X_text['returnsOpenNextMktres10'].apply(round_scores)\n\n        # convert tuples to string format if applicable\n        def tuple_to_str(x):\n            try:\n                if isinstance(x, tuple):\n                    return ' '.join(x)\n                else:\n                    return x\n            except ValueError:\n                return np.nan\n            \n        X_text[self.col] = X_text[self.col].apply(tuple_to_str)\n\n        # get lists\n        text_lst = list(X_text[self.col])\n        target_lst = list(X_text['returnsOpenNextMktres10'])\n\n        # vectorize text features\n        vectorizer = CountVectorizer()\n        text_vectorized = vectorizer.fit_transform(text_lst)\n\n        # model data (will use other modelling methods in the future)\n        text_model = LogisticRegression()\n        text_model = text_model.fit(text_vectorized, target_lst)\n\n        # get coefficients\n        basictext = vectorizer.get_feature_names()\n        basiccoeffs = text_model.coef_.tolist()[0]\n        coeff_df = pd.DataFrame({'Text' : basictext, \n                                'Coefficient' : basiccoeffs})\n\n        # convert dataframe to dictionary of coefficients\n        self.coeff_dict = dict(zip(coeff_df.Text, coeff_df.Coefficient))\n\n        # get value that accounts for nulls\n        self.coeff_default = coeff_df['Coefficient'].mean()\n\n    def predict_data(self, X_):\n\n        def get_coeff(x):\n            \n            try:\n\n                # iterate through each set of text data\n                coeff_total_score = 0\n                \n                if isinstance(x, tuple):\n                    x = ' '.join(x)\n                    \n                if isinstance(x, str):\n                    x = [x]\n                \n                for textset in x:\n\n                    text_lst = textset.split(' ')\n                \n                    # iter through every word\n                    coeff_sum = 0\n                    for text in text_lst:\n                        text = text.lower()\n                        if text in self.coeff_dict:\n                            coeff_sum += self.coeff_dict[text]\n                        else:\n                            coeff_sum += self.coeff_default\n\n                    # get average coefficient\n                    coeff_total_score += coeff_sum / len(text_lst)\n\n                return coeff_total_score / len(x)\n            \n            except TypeError:\n                \n                return np.nan\n\n        X_[self.col + '_coeff_mean'] = X_[self.col].apply(get_coeff)\n        \n        return X_\n\n    # obtain target volumn\n    def __init__(self, input_col):\n        self.col = input_col",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "90878febb77aa9c2a14f420fedc3a8763e019e4e"
      },
      "cell_type": "code",
      "source": "def text_processing_train(X):\n    \n    # get list of text to coeff converters [headline, subjects, audiences]\n    text_to_coeff_lst = []\n#     for f in ['headline', 'subjects', 'audiences']:\n    for f in ['headline']:\n        text_to_coeff = TextToCoeff(f)\n        text_to_coeff.vectorize(X)\n        text_to_coeff_lst.append(text_to_coeff)\n    \n    return text_to_coeff_lst\n\ndef text_processing_test(X, text_to_coeff_lst):\n    \n    for text_to_coeff in text_to_coeff_lst:\n        X = text_to_coeff.predict_data(X)\n        \n    del X['headline']\n#     del X['subjects']\n#     del X['audiences']\n    gc.collect()\n    \n    return X",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ce0e7f1799a9199300876768e5e758688628dbbb"
      },
      "cell_type": "code",
      "source": "%%time\ntext_to_coeff_lst = text_processing_train(X_train)\nX_train = text_processing_test(X_train, text_to_coeff_lst)",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "CPU times: user 1.5 s, sys: 4 ms, total: 1.5 s\nWall time: 1.51 s\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "bb3b997307f60939c4b4a36845dc264109f60c81"
      },
      "cell_type": "markdown",
      "source": "### Entire Market and Individual Asset Lag Features\nWe are going to be obtaining Quant Features from both the entire market dataframe and from each individual asset based on assetCode.\n\nSource: https://www.kaggle.com/qqgeogor/eda-script-67"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "40c71a4a4b0d16255a0d8df0eaed31353850608e"
      },
      "cell_type": "code",
      "source": "from multiprocessing import Pool\n\ndef create_lag(df_code,n_lag=[3,7,14,],shift_size=1):\n    code = df_code['assetCode'].unique()\n    \n    for col in return_features:\n        for window in n_lag:\n            rolled = df_code[col].shift(shift_size).rolling(window=window)\n            lag_mean = rolled.mean()\n            lag_max = rolled.max()\n            lag_min = rolled.min()\n            lag_std = rolled.std()\n            df_code['%s_lag_%s_mean'%(col,window)] = lag_mean\n            df_code['%s_lag_%s_max'%(col,window)] = lag_max\n            df_code['%s_lag_%s_min'%(col,window)] = lag_min\n\n    return df_code.fillna(-1)\n\ndef generate_lag_features(df,n_lag = [3,7,14]):\n    \n    assetCodes = df['assetCode'].unique()\n    all_df = []\n    df_codes = df.groupby('assetCode')\n    df_codes = [df_code[1][['time','assetCode']+return_features] for df_code in df_codes]\n    \n    pool = Pool(4)\n    all_df = pool.map(create_lag, df_codes)\n    \n    new_df = pd.concat(all_df)  \n    new_df.drop(return_features+['time', 'assetCode'],axis=1,inplace=True)\n    new_df = pd.concat([df, new_df], axis=1, sort=False)\n    pool.close()\n    \n    return new_df",
      "execution_count": 27,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3e74748b76d9486be16965296832163b8030d1aa"
      },
      "cell_type": "code",
      "source": "%%time\nreturn_features = ['returnsClosePrevMktres10','returnsClosePrevRaw10','open','close', 'volume']\nX_train = generate_lag_features(X_train)",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": "CPU times: user 7.54 s, sys: 3.77 s, total: 11.3 s\nWall time: 45.3 s\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "41ffe3d7dba3f05b87677d58eb65af8025ab6987"
      },
      "cell_type": "code",
      "source": "X_train.dropna().head()",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "                          time        ...        volume_lag_14_min\n3522 2015-01-06 22:00:00+00:00        ...                     -1.0\n4811 2015-01-06 22:00:00+00:00        ...                     -1.0\n5424 2015-01-07 22:00:00+00:00        ...                     -1.0\n5836 2015-01-07 22:00:00+00:00        ...                     -1.0\n6557 2015-01-07 22:00:00+00:00        ...                     -1.0\n\n[5 rows x 56 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>assetCode</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n      <th>headline_coeff_mean</th>\n      <th>returnsClosePrevMktres10_lag_3_mean</th>\n      <th>returnsClosePrevMktres10_lag_3_max</th>\n      <th>returnsClosePrevMktres10_lag_3_min</th>\n      <th>returnsClosePrevMktres10_lag_7_mean</th>\n      <th>returnsClosePrevMktres10_lag_7_max</th>\n      <th>returnsClosePrevMktres10_lag_7_min</th>\n      <th>returnsClosePrevMktres10_lag_14_mean</th>\n      <th>returnsClosePrevMktres10_lag_14_max</th>\n      <th>returnsClosePrevMktres10_lag_14_min</th>\n      <th>returnsClosePrevRaw10_lag_3_mean</th>\n      <th>returnsClosePrevRaw10_lag_3_max</th>\n      <th>returnsClosePrevRaw10_lag_3_min</th>\n      <th>returnsClosePrevRaw10_lag_7_mean</th>\n      <th>returnsClosePrevRaw10_lag_7_max</th>\n      <th>returnsClosePrevRaw10_lag_7_min</th>\n      <th>returnsClosePrevRaw10_lag_14_mean</th>\n      <th>returnsClosePrevRaw10_lag_14_max</th>\n      <th>returnsClosePrevRaw10_lag_14_min</th>\n      <th>open_lag_3_mean</th>\n      <th>open_lag_3_max</th>\n      <th>open_lag_3_min</th>\n      <th>open_lag_7_mean</th>\n      <th>open_lag_7_max</th>\n      <th>open_lag_7_min</th>\n      <th>open_lag_14_mean</th>\n      <th>open_lag_14_max</th>\n      <th>open_lag_14_min</th>\n      <th>close_lag_3_mean</th>\n      <th>close_lag_3_max</th>\n      <th>close_lag_3_min</th>\n      <th>close_lag_7_mean</th>\n      <th>close_lag_7_max</th>\n      <th>close_lag_7_min</th>\n      <th>close_lag_14_mean</th>\n      <th>close_lag_14_max</th>\n      <th>close_lag_14_min</th>\n      <th>volume_lag_3_mean</th>\n      <th>volume_lag_3_max</th>\n      <th>volume_lag_3_min</th>\n      <th>volume_lag_7_mean</th>\n      <th>volume_lag_7_max</th>\n      <th>volume_lag_7_min</th>\n      <th>volume_lag_14_mean</th>\n      <th>volume_lag_14_max</th>\n      <th>volume_lag_14_min</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3522</th>\n      <td>2015-01-06 22:00:00+00:00</td>\n      <td>BERY.N</td>\n      <td>1773553.0</td>\n      <td>31.82</td>\n      <td>31.85</td>\n      <td>0.042937</td>\n      <td>0.034427</td>\n      <td>0.052021</td>\n      <td>0.040911</td>\n      <td>0.033266</td>\n      <td>0.052720</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>-1.00</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>-1.00</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.000000e+00</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>4811</th>\n      <td>2015-01-06 22:00:00+00:00</td>\n      <td>TRMK.O</td>\n      <td>459378.0</td>\n      <td>23.06</td>\n      <td>23.63</td>\n      <td>-0.063363</td>\n      <td>-0.022342</td>\n      <td>-0.029527</td>\n      <td>-0.004954</td>\n      <td>-0.072428</td>\n      <td>-0.029931</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>-1.00</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>-1.00</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.000000e+00</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>5424</th>\n      <td>2015-01-07 22:00:00+00:00</td>\n      <td>DB.N</td>\n      <td>2689385.0</td>\n      <td>28.66</td>\n      <td>28.61</td>\n      <td>-0.070084</td>\n      <td>-0.071405</td>\n      <td>-0.045118</td>\n      <td>-0.043554</td>\n      <td>0.021101</td>\n      <td>0.087410</td>\n      <td>-0.041690</td>\n      <td>-0.021221</td>\n      <td>-0.061425</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-0.052338</td>\n      <td>0.001973</td>\n      <td>-0.082166</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>29.636667</td>\n      <td>30.59</td>\n      <td>28.96</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>29.216667</td>\n      <td>30.47</td>\n      <td>28.36</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>2.787095e+06</td>\n      <td>3302828.0</td>\n      <td>2273233.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>5836</th>\n      <td>2015-01-07 22:00:00+00:00</td>\n      <td>KND.N</td>\n      <td>1846453.0</td>\n      <td>17.83</td>\n      <td>17.16</td>\n      <td>-0.029924</td>\n      <td>-0.047196</td>\n      <td>-0.006754</td>\n      <td>-0.016487</td>\n      <td>0.085713</td>\n      <td>0.095380</td>\n      <td>-0.040549</td>\n      <td>-0.020379</td>\n      <td>-0.053088</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-0.049903</td>\n      <td>-0.031080</td>\n      <td>-0.067633</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>17.800000</td>\n      <td>18.34</td>\n      <td>17.37</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>17.420000</td>\n      <td>17.77</td>\n      <td>17.12</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>1.524299e+06</td>\n      <td>2014114.0</td>\n      <td>959873.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>6557</th>\n      <td>2015-01-07 22:00:00+00:00</td>\n      <td>VIAB.O</td>\n      <td>3639112.0</td>\n      <td>71.30</td>\n      <td>72.35</td>\n      <td>-0.066510</td>\n      <td>-0.047525</td>\n      <td>-0.037256</td>\n      <td>-0.014685</td>\n      <td>-0.077258</td>\n      <td>-0.061035</td>\n      <td>-0.008926</td>\n      <td>0.002563</td>\n      <td>-0.017463</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-0.020317</td>\n      <td>0.024874</td>\n      <td>-0.053609</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>74.696667</td>\n      <td>75.83</td>\n      <td>73.46</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>73.516667</td>\n      <td>75.40</td>\n      <td>71.85</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>2.896212e+06</td>\n      <td>3568991.0</td>\n      <td>1976737.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "bc5e1e76b0da8d54944b2f052a260c6262b0c14b"
      },
      "cell_type": "markdown",
      "source": "### Misc. Features\nInclues the following features:\n* Daily Difference"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "efb62b12fc7e92dc4ca1047faa85e796b33f2847"
      },
      "cell_type": "code",
      "source": "def misc_features(X):\n    \n    # Adding daily difference\n    new_col = X[\"close\"] - X[\"open\"]\n    X.insert(loc=6, column=\"daily_diff\", value=new_col)\n    X['close_to_open'] =  np.abs(X['close'] / X['open'])\n    \n    # extra features\n    X['bartrend'] = X['close'] / X['open']\n    X['average'] = (X['close'] + X['open'])/2\n    X['pricevolume'] = X['volume'] * X['close']\n",
      "execution_count": 30,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "522167cbd0bff9410e5fdab6b4b7ccabbef85b73"
      },
      "cell_type": "code",
      "source": "misc_features(X_train)",
      "execution_count": 31,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a43e6531abec41d694afed23ddb3c34ea113bda5"
      },
      "cell_type": "code",
      "source": "X_train.dropna().tail()",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "                            time assetCode      ...       average   pricevolume\n880118 2016-12-21 22:00:00+00:00    GOOG.O      ...       795.200  9.624871e+08\n880119 2016-12-21 22:00:00+00:00   GOOGL.O      ...       813.960  1.185510e+09\n880182 2016-12-21 22:00:00+00:00     HMC.N      ...        30.050  1.522858e+07\n882475 2016-12-22 22:00:00+00:00     PBH.N      ...        48.940  1.774014e+07\n883039 2016-12-22 22:00:00+00:00    XLRN.O      ...        26.705  1.523876e+07\n\n[5 rows x 61 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>assetCode</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>daily_diff</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n      <th>headline_coeff_mean</th>\n      <th>returnsClosePrevMktres10_lag_3_mean</th>\n      <th>returnsClosePrevMktres10_lag_3_max</th>\n      <th>returnsClosePrevMktres10_lag_3_min</th>\n      <th>returnsClosePrevMktres10_lag_7_mean</th>\n      <th>returnsClosePrevMktres10_lag_7_max</th>\n      <th>returnsClosePrevMktres10_lag_7_min</th>\n      <th>returnsClosePrevMktres10_lag_14_mean</th>\n      <th>returnsClosePrevMktres10_lag_14_max</th>\n      <th>returnsClosePrevMktres10_lag_14_min</th>\n      <th>returnsClosePrevRaw10_lag_3_mean</th>\n      <th>returnsClosePrevRaw10_lag_3_max</th>\n      <th>returnsClosePrevRaw10_lag_3_min</th>\n      <th>returnsClosePrevRaw10_lag_7_mean</th>\n      <th>returnsClosePrevRaw10_lag_7_max</th>\n      <th>returnsClosePrevRaw10_lag_7_min</th>\n      <th>returnsClosePrevRaw10_lag_14_mean</th>\n      <th>returnsClosePrevRaw10_lag_14_max</th>\n      <th>returnsClosePrevRaw10_lag_14_min</th>\n      <th>open_lag_3_mean</th>\n      <th>open_lag_3_max</th>\n      <th>open_lag_3_min</th>\n      <th>open_lag_7_mean</th>\n      <th>open_lag_7_max</th>\n      <th>open_lag_7_min</th>\n      <th>open_lag_14_mean</th>\n      <th>open_lag_14_max</th>\n      <th>open_lag_14_min</th>\n      <th>close_lag_3_mean</th>\n      <th>close_lag_3_max</th>\n      <th>close_lag_3_min</th>\n      <th>close_lag_7_mean</th>\n      <th>close_lag_7_max</th>\n      <th>close_lag_7_min</th>\n      <th>close_lag_14_mean</th>\n      <th>close_lag_14_max</th>\n      <th>close_lag_14_min</th>\n      <th>volume_lag_3_mean</th>\n      <th>volume_lag_3_max</th>\n      <th>volume_lag_3_min</th>\n      <th>volume_lag_7_mean</th>\n      <th>volume_lag_7_max</th>\n      <th>volume_lag_7_min</th>\n      <th>volume_lag_14_mean</th>\n      <th>volume_lag_14_max</th>\n      <th>volume_lag_14_min</th>\n      <th>close_to_open</th>\n      <th>bartrend</th>\n      <th>average</th>\n      <th>pricevolume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>880118</th>\n      <td>2016-12-21 22:00:00+00:00</td>\n      <td>GOOG.O</td>\n      <td>1211346.0</td>\n      <td>794.56</td>\n      <td>795.84</td>\n      <td>0.030304</td>\n      <td>-1.28</td>\n      <td>0.045782</td>\n      <td>0.008581</td>\n      <td>-0.002074</td>\n      <td>0.009318</td>\n      <td>0.145861</td>\n      <td>0.015027</td>\n      <td>0.030231</td>\n      <td>0.000888</td>\n      <td>0.026553</td>\n      <td>0.049086</td>\n      <td>0.000888</td>\n      <td>0.011370</td>\n      <td>0.049086</td>\n      <td>-0.028080</td>\n      <td>0.048131</td>\n      <td>0.053698</td>\n      <td>0.041546</td>\n      <td>0.046112</td>\n      <td>0.066758</td>\n      <td>0.027374</td>\n      <td>0.023147</td>\n      <td>0.066758</td>\n      <td>-0.026879</td>\n      <td>795.793333</td>\n      <td>800.40</td>\n      <td>790.22</td>\n      <td>794.437143</td>\n      <td>800.40</td>\n      <td>785.04</td>\n      <td>778.500714</td>\n      <td>800.40</td>\n      <td>744.59</td>\n      <td>793.806667</td>\n      <td>796.42</td>\n      <td>790.80</td>\n      <td>794.530000</td>\n      <td>797.85</td>\n      <td>789.27</td>\n      <td>779.904286</td>\n      <td>797.85</td>\n      <td>747.92</td>\n      <td>1.542299e+06</td>\n      <td>2443796.0</td>\n      <td>951014.0</td>\n      <td>1.743839e+06</td>\n      <td>2443796.0</td>\n      <td>951014.0</td>\n      <td>1.773797e+06</td>\n      <td>3017947.0</td>\n      <td>951014.0</td>\n      <td>0.998392</td>\n      <td>0.998392</td>\n      <td>795.200</td>\n      <td>9.624871e+08</td>\n    </tr>\n    <tr>\n      <th>880119</th>\n      <td>2016-12-21 22:00:00+00:00</td>\n      <td>GOOGL.O</td>\n      <td>1459628.0</td>\n      <td>812.20</td>\n      <td>815.72</td>\n      <td>0.026192</td>\n      <td>-3.52</td>\n      <td>0.045862</td>\n      <td>0.004218</td>\n      <td>-0.000078</td>\n      <td>0.013145</td>\n      <td>0.145861</td>\n      <td>0.020601</td>\n      <td>0.039960</td>\n      <td>0.003058</td>\n      <td>0.032340</td>\n      <td>0.054876</td>\n      <td>0.003058</td>\n      <td>0.015764</td>\n      <td>0.054876</td>\n      <td>-0.028711</td>\n      <td>0.051228</td>\n      <td>0.059362</td>\n      <td>0.044049</td>\n      <td>0.047988</td>\n      <td>0.067144</td>\n      <td>0.028137</td>\n      <td>0.024758</td>\n      <td>0.067144</td>\n      <td>-0.027603</td>\n      <td>813.653333</td>\n      <td>818.31</td>\n      <td>809.28</td>\n      <td>813.064286</td>\n      <td>818.31</td>\n      <td>804.82</td>\n      <td>796.735000</td>\n      <td>818.31</td>\n      <td>761.90</td>\n      <td>812.513333</td>\n      <td>815.20</td>\n      <td>809.84</td>\n      <td>813.474286</td>\n      <td>817.89</td>\n      <td>807.90</td>\n      <td>798.114286</td>\n      <td>817.89</td>\n      <td>764.33</td>\n      <td>1.711443e+06</td>\n      <td>2598866.0</td>\n      <td>1263581.0</td>\n      <td>1.780074e+06</td>\n      <td>2598866.0</td>\n      <td>1263581.0</td>\n      <td>1.858244e+06</td>\n      <td>2867074.0</td>\n      <td>1263581.0</td>\n      <td>0.995685</td>\n      <td>0.995685</td>\n      <td>813.960</td>\n      <td>1.185510e+09</td>\n    </tr>\n    <tr>\n      <th>880182</th>\n      <td>2016-12-21 22:00:00+00:00</td>\n      <td>HMC.N</td>\n      <td>507281.0</td>\n      <td>30.02</td>\n      <td>30.08</td>\n      <td>0.000000</td>\n      <td>-0.06</td>\n      <td>0.013136</td>\n      <td>0.002266</td>\n      <td>0.024439</td>\n      <td>0.006083</td>\n      <td>0.145861</td>\n      <td>0.034245</td>\n      <td>0.035138</td>\n      <td>0.033067</td>\n      <td>0.033763</td>\n      <td>0.041578</td>\n      <td>0.021137</td>\n      <td>0.033442</td>\n      <td>0.056021</td>\n      <td>0.012214</td>\n      <td>0.024689</td>\n      <td>0.026164</td>\n      <td>0.022026</td>\n      <td>0.023488</td>\n      <td>0.031762</td>\n      <td>0.009079</td>\n      <td>0.030351</td>\n      <td>0.057183</td>\n      <td>0.009079</td>\n      <td>30.146667</td>\n      <td>30.21</td>\n      <td>30.10</td>\n      <td>30.160000</td>\n      <td>30.21</td>\n      <td>30.09</td>\n      <td>29.937857</td>\n      <td>30.34</td>\n      <td>29.31</td>\n      <td>30.163333</td>\n      <td>30.20</td>\n      <td>30.13</td>\n      <td>30.171429</td>\n      <td>30.30</td>\n      <td>30.01</td>\n      <td>30.007143</td>\n      <td>30.63</td>\n      <td>29.37</td>\n      <td>5.667863e+05</td>\n      <td>854758.0</td>\n      <td>391865.0</td>\n      <td>6.697453e+05</td>\n      <td>1054597.0</td>\n      <td>391865.0</td>\n      <td>7.215958e+05</td>\n      <td>1054597.0</td>\n      <td>391865.0</td>\n      <td>0.998005</td>\n      <td>0.998005</td>\n      <td>30.050</td>\n      <td>1.522858e+07</td>\n    </tr>\n    <tr>\n      <th>882475</th>\n      <td>2016-12-22 22:00:00+00:00</td>\n      <td>PBH.N</td>\n      <td>363975.0</td>\n      <td>48.74</td>\n      <td>49.14</td>\n      <td>0.047496</td>\n      <td>-0.40</td>\n      <td>0.050224</td>\n      <td>0.023523</td>\n      <td>0.008091</td>\n      <td>0.070904</td>\n      <td>0.134257</td>\n      <td>-0.043596</td>\n      <td>0.005349</td>\n      <td>-0.076473</td>\n      <td>-0.055516</td>\n      <td>0.005349</td>\n      <td>-0.095553</td>\n      <td>-0.075657</td>\n      <td>0.005349</td>\n      <td>-0.118269</td>\n      <td>0.056050</td>\n      <td>0.059417</td>\n      <td>0.053082</td>\n      <td>0.055421</td>\n      <td>0.079802</td>\n      <td>0.023899</td>\n      <td>0.004650</td>\n      <td>0.079802</td>\n      <td>-0.078879</td>\n      <td>49.586667</td>\n      <td>49.70</td>\n      <td>49.51</td>\n      <td>49.475714</td>\n      <td>50.42</td>\n      <td>48.07</td>\n      <td>48.047857</td>\n      <td>50.42</td>\n      <td>46.35</td>\n      <td>49.303333</td>\n      <td>49.39</td>\n      <td>49.20</td>\n      <td>49.534286</td>\n      <td>50.20</td>\n      <td>49.20</td>\n      <td>48.198571</td>\n      <td>50.20</td>\n      <td>46.36</td>\n      <td>3.317723e+05</td>\n      <td>358254.0</td>\n      <td>292139.0</td>\n      <td>5.680126e+05</td>\n      <td>1416838.0</td>\n      <td>292139.0</td>\n      <td>5.008767e+05</td>\n      <td>1416838.0</td>\n      <td>292139.0</td>\n      <td>0.991860</td>\n      <td>0.991860</td>\n      <td>48.940</td>\n      <td>1.774014e+07</td>\n    </tr>\n    <tr>\n      <th>883039</th>\n      <td>2016-12-22 22:00:00+00:00</td>\n      <td>XLRN.O</td>\n      <td>580303.0</td>\n      <td>26.26</td>\n      <td>27.15</td>\n      <td>-0.165820</td>\n      <td>-0.89</td>\n      <td>-0.124194</td>\n      <td>-0.147845</td>\n      <td>-0.113162</td>\n      <td>0.032059</td>\n      <td>0.078197</td>\n      <td>-0.242522</td>\n      <td>-0.109602</td>\n      <td>-0.369297</td>\n      <td>-0.426109</td>\n      <td>-0.109602</td>\n      <td>-0.632957</td>\n      <td>-0.384752</td>\n      <td>-0.068863</td>\n      <td>-0.632957</td>\n      <td>-0.152812</td>\n      <td>-0.112080</td>\n      <td>-0.174785</td>\n      <td>-0.163599</td>\n      <td>-0.112080</td>\n      <td>-0.190307</td>\n      <td>-0.154126</td>\n      <td>-0.048755</td>\n      <td>-0.218009</td>\n      <td>28.946667</td>\n      <td>29.88</td>\n      <td>28.13</td>\n      <td>29.047143</td>\n      <td>29.88</td>\n      <td>28.13</td>\n      <td>31.130714</td>\n      <td>37.22</td>\n      <td>28.13</td>\n      <td>28.146667</td>\n      <td>28.80</td>\n      <td>27.49</td>\n      <td>28.800000</td>\n      <td>29.66</td>\n      <td>27.49</td>\n      <td>30.529286</td>\n      <td>36.29</td>\n      <td>27.49</td>\n      <td>2.629113e+05</td>\n      <td>293882.0</td>\n      <td>209869.0</td>\n      <td>4.026397e+05</td>\n      <td>754904.0</td>\n      <td>209869.0</td>\n      <td>4.735576e+05</td>\n      <td>754904.0</td>\n      <td>209869.0</td>\n      <td>0.967219</td>\n      <td>0.967219</td>\n      <td>26.705</td>\n      <td>1.523876e+07</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9a69dad5e4480701ff63f383d1d12c395fe8493c"
      },
      "cell_type": "code",
      "source": "def data_step2(X_test):\n    \n    X_test = generate_lag_features(X_test)\n    X_test = text_processing_test(X_test, text_to_coeff_lst)\n    misc_features(X_test)\n    \n    return X_test",
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ab3199b41454b6093f0cd2be4dddf3b869824596"
      },
      "cell_type": "markdown",
      "source": "<a id='section3'></a>\n## Step 3. Modelling using LightGBM"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f188468c50fc2ffb9c145c9ebd5addcd36428964"
      },
      "cell_type": "code",
      "source": "traincols = [f for f in X_train.columns if f not in ['time', 'assetCode', 'universe', 'assetName', \\\n                                                     'returnsOpenNextMktres10','headline']]\n\n# classify data\ny_train = (X_train['returnsOpenNextMktres10'] > 0).astype(int)\nX_train = X_train[traincols].fillna(0)",
      "execution_count": 34,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "76abdc01a2846fe429c2364a2a21cecae3e92fc0"
      },
      "cell_type": "markdown",
      "source": "### Fixed Training Split\nThe reason why we need to do a fixed training test split that fetches the last few rows of the training dataset is to avoid odd results, since randomly choosing rows will cause the validation dataset to be filled with rows with different timestamps."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96cba104e412b54f84ec6f348c633df92577c90c"
      },
      "cell_type": "code",
      "source": "def fixed_train_test_split(X, y, train_size):\n    \n    # round train size\n    train_size = int(train_size * len(X))\n    \n    # split data\n    X_train, y_train = X[train_size:].values, y[train_size:].values\n    X_valid, y_valid = X[:train_size].values, y[:train_size].values\n    \n    return X_train, y_train, X_valid, y_valid",
      "execution_count": 35,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f554061d572cb8f8fd06cef48c3ef633e9db17d0"
      },
      "cell_type": "code",
      "source": "X_train, y_train, X_valid, y_valid = fixed_train_test_split(X_train, y_train, 0.85)",
      "execution_count": 36,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2650f95fdad878de3188d131227fda5a1974b728"
      },
      "cell_type": "code",
      "source": "# Scaling of X values\n# It is good to keep these scaling values for later\nmins = np.min(X_train, axis=0)\nmaxs = np.max(X_train, axis=0)\nrng = maxs - mins\nX_train = 1 - ((maxs - X_train) / rng)",
      "execution_count": 37,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "555aa54327cc8ffdacc43554af32d5105c775169"
      },
      "cell_type": "markdown",
      "source": "### Using LightGBM for modelling\n\nModels from https://www.kaggle.com/qqgeogor/eda-script-67"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "767fb9d152e002da46861bc0607bdd51f41828e1"
      },
      "cell_type": "code",
      "source": "%%time\n\nimport lightgbm as lgb\n\n# these are tuned params I found\nx_1 = [0.19000424246380565, 2452, 212, 328, 202]\nx_2 = [0.19016805202090095, 2583, 213, 312, 220]\n\ntrain_data, test_data = lgb.Dataset(X_train, y_train), lgb.Dataset(X_valid, y_valid)\n\nparams_1 = {\n        'task': 'train',\n        'boosting_type': 'gbdt',\n        'objective': 'binary',\n#         'objective': 'regression',\n        'learning_rate': x_1[0],\n        'num_leaves': x_1[1],\n        'min_data_in_leaf': x_1[2],\n#         'num_iteration': x_1[3],\n        'num_iteration': 239,\n        'max_bin': x_1[4],\n        'verbose': 1\n    }\n\nparams_2 = {\n        'task': 'train',\n        'boosting_type': 'gbdt',\n        'objective': 'binary',\n#         'objective': 'regression',\n        'learning_rate': x_2[0],\n        'num_leaves': x_2[1],\n        'min_data_in_leaf': x_2[2],\n#         'num_iteration': x_2[3],\n        'num_iteration': 172,\n        'max_bin': x_2[4],\n        'verbose': 1\n    }\n\ngbm_1 = lgb.train(params_1,\n        train_data,\n        num_boost_round=100,\n        valid_sets=test_data,\n        early_stopping_rounds=5,\n#         fobj=exp_loss,\n        )\n\ngbm_2 = lgb.train(params_2,\n        train_data,\n        num_boost_round=100,\n        valid_sets=test_data,\n        early_stopping_rounds=5,\n#         fobj=exp_loss,\n        )\n",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[1]\tvalid_0's binary_logloss: 0.70505\nTraining until validation scores don't improve for 5 rounds.\n[2]\tvalid_0's binary_logloss: 0.72542\n[3]\tvalid_0's binary_logloss: 0.756944\n[4]\tvalid_0's binary_logloss: 0.792997\n[5]\tvalid_0's binary_logloss: 0.835192\n[6]\tvalid_0's binary_logloss: 0.856446\nEarly stopping, best iteration is:\n[1]\tvalid_0's binary_logloss: 0.70505\n[1]\tvalid_0's binary_logloss: 0.705068\nTraining until validation scores don't improve for 5 rounds.\n[2]\tvalid_0's binary_logloss: 0.724581\n[3]\tvalid_0's binary_logloss: 0.757593\n[4]\tvalid_0's binary_logloss: 0.798879\n[5]\tvalid_0's binary_logloss: 0.811772\n[6]\tvalid_0's binary_logloss: 0.854176\nEarly stopping, best iteration is:\n[1]\tvalid_0's binary_logloss: 0.705068\nCPU times: user 12.2 s, sys: 1.15 s, total: 13.4 s\nWall time: 3.98 s\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "36a59163f089651745eaf40bb6250261a23aab24"
      },
      "cell_type": "markdown",
      "source": "<a id='section4'></a>\n## Step 4. Applying the Model\n"
    },
    {
      "metadata": {
        "_uuid": "f20c20364f574cded4dd1fb93f0183d88a58657e"
      },
      "cell_type": "markdown",
      "source": "Predictions will be made through a for loop, and apply all the functions above onto the test dataset."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7b135a2631912100c434e78d21269b6aed4c4e37"
      },
      "cell_type": "code",
      "source": "def get_X(market_test_df, news_test_df):\n    X_test = data_step1(market_test_df, news_test_df)\n    X_test = data_step2(X_test)\n    X_test = X_test[[f for f in X_test.columns if f not in ['time', 'assetCode', 'universe', 'assetName', 'returnsOpenNextMktres10',\n                                                          'headline', 'subjects', 'audiences']]].fillna(0).values\n    return X_test\n\ndef make_predictions(market_obs_df, news_obs_df):\n    \n    # predict using given model\n    X_test = get_X(market_obs_df, news_obs_df)\n    X_test = 1 - ((maxs - X_test) / rng)\n    prediction_values = (gbm_1.predict(X_test) + gbm_2.predict(X_test))/2\n    prediction_values = (prediction_values-prediction_values.min())/(prediction_values.max()-prediction_values.min())\n    prediction_values = prediction_values * 2 - 1\n\n    return prediction_values\n",
      "execution_count": 39,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73d421583382e278112c0a8e10e617a4582e072f"
      },
      "cell_type": "code",
      "source": "%%time\nn_days = 0\nfor (market_obs_df, news_obs_df, predictions_template_df) in env.get_prediction_days(): # Looping over days from start of 2017 to 2019-07-15\n    \n    n_days +=1\n    if n_days % 50 == 0:\n        print(n_days)\n    \n    # make predictions\n    predictions_template_df['confidenceValue'] = make_predictions(market_obs_df, news_obs_df)\n    \n    # save predictions\n    env.predict(predictions_template_df)\n    \nenv.write_submission_file()",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": "1.0 -1.0\n1.0 -1.0\n1.0 -1.0\n1.0 -1.0\n1.0 -1.0\n1.0 -1.0\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Process ForkPoolWorker-30:\nProcess ForkPoolWorker-31:\nProcess ForkPoolWorker-29:\nProcess ForkPoolWorker-32:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-27-8a324a7b1665>\", line 10, in create_lag\n    lag_max = rolled.max()\nTraceback (most recent call last):\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/window.py\", line 1593, in max\n    return super(Rolling, self).max(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/window.py\", line 1015, in max\n    return self._apply('roll_max', 'max', **kwargs)\n  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/window.py\", line 844, in _apply\n    values = self._prep_values(b.values)\n  File \"<ipython-input-27-8a324a7b1665>\", line 12, in create_lag\n    lag_std = rolled.std()\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/window.py\", line 228, in _prep_values\n    values = values.copy()\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/window.py\", line 1616, in std\n    return super(Rolling, self).std(ddof=ddof, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/window.py\", line 1167, in std\n    ddof=ddof, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/window.py\", line 840, in _apply\n    blocks, obj, index = self._create_blocks()\n  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/window.py\", line 128, in _create_blocks\n    blocks = obj._to_dict_of_blocks(copy=False).values()\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\", line 4888, in _to_dict_of_blocks\n    for k, v, in self._data.to_dict(copy=copy).items()}\n  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\", line 4009, in to_dict\n    for dtype, blocks in bd.items()}\n  File \"<ipython-input-27-8a324a7b1665>\", line 11, in create_lag\n    lag_min = rolled.min()\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\", line 4009, in <dictcomp>\n    for dtype, blocks in bd.items()}\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\", line 3865, in combine\n    axes[0] = self.items.take(indexer)\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/window.py\", line 1599, in min\n    return super(Rolling, self).min(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 2195, in take\n    return self._shallow_copy(taken)\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/window.py\", line 1054, in min\n    return self._apply('roll_min', 'min', **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/numeric.py\", line 68, in _shallow_copy\n    return self._shallow_copy_with_infer(values=values, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/window.py\", line 840, in _apply\n    blocks, obj, index = self._create_blocks()\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 537, in _shallow_copy_with_infer\n    attributes['copy'] = False\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/window.py\", line 128, in _create_blocks\n    blocks = obj._to_dict_of_blocks(copy=False).values()\n  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\", line 4888, in _to_dict_of_blocks\n    for k, v, in self._data.to_dict(copy=copy).items()}\n  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\", line 4009, in to_dict\n    for dtype, blocks in bd.items()}\n  File \"<ipython-input-27-8a324a7b1665>\", line 12, in create_lag\n    lag_std = rolled.std()\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/window.py\", line 1616, in std\n    return super(Rolling, self).std(ddof=ddof, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\", line 4009, in <dictcomp>\n    for dtype, blocks in bd.items()}\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\", line 3854, in combine\n    for b in blocks]))\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/window.py\", line 1167, in std\n    ddof=ddof, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/window.py\", line 840, in _apply\n    blocks, obj, index = self._create_blocks()\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/window.py\", line 128, in _create_blocks\n    blocks = obj._to_dict_of_blocks(copy=False).values()\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\", line 4888, in _to_dict_of_blocks\n    for k, v, in self._data.to_dict(copy=copy).items()}\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\", line 4009, in to_dict\n    for dtype, blocks in bd.items()}\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\", line 4009, in <dictcomp>\n    for dtype, blocks in bd.items()}\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\", line 3865, in combine\n    axes[0] = self.items.take(indexer)\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 2195, in take\n    return self._shallow_copy(taken)\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/numeric.py\", line 68, in _shallow_copy\n    return self._shallow_copy_with_infer(values=values, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 545, in _shallow_copy_with_infer\n    return Index(values, **attributes)\n  File \"/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 264, in __new__\n    from .range import RangeIndex\nKeyboardInterrupt\n",
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-f557b8869693>\u001b[0m in \u001b[0;36mmake_predictions\u001b[0;34m(market_obs_df, news_obs_df)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# predict using given model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarket_obs_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnews_obs_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprediction_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgbm_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgbm_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-f557b8869693>\u001b[0m in \u001b[0;36mget_X\u001b[0;34m(market_test_df, news_test_df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarket_test_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnews_test_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_step1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarket_test_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnews_test_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_step2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     X_test = X_test[[f for f in X_test.columns if f not in ['time', 'assetCode', 'universe', 'assetName', 'returnsOpenNextMktres10',\n\u001b[1;32m      5\u001b[0m                                                           'headline', 'subjects', 'audiences']]].fillna(0).values\n",
            "\u001b[0;32m<ipython-input-33-2ea01413acc8>\u001b[0m in \u001b[0;36mdata_step2\u001b[0;34m(X_test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_step2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_lag_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_processing_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_to_coeff_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmisc_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-8a324a7b1665>\u001b[0m in \u001b[0;36mgenerate_lag_features\u001b[0;34m(df, n_lag)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mall_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_lag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_codes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "cbcb1733a22212e40026b5bafdbb982b667446d6"
      },
      "cell_type": "markdown",
      "source": "**Sources:**\n* [Market Data NN Baseline by Christofhenkel](https://www.kaggle.com/christofhenkel/market-data-nn-baseline)\n* [A simple model using the market and news data by Bguberfain](https://www.kaggle.com/bguberfain/a-simple-model-using-the-market-and-news-data)\n* [Amateur Hour - Using Headlines to Predict Stocks by Magichanics](https://www.kaggle.com/magichanics/amateur-hour-using-headlines-to-predict-stocks)\n* [Simple Quant Features by Youhanlee](https://www.kaggle.com/youhanlee/simple-quant-features-using-python)\n* [>0.64 in 100 lines by rabaman](https://www.kaggle.com/rabaman/0-64-in-100-lines/comments)\n* [eda script 67 by qqgeogor](https://www.kaggle.com/qqgeogor/eda-script-67)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}