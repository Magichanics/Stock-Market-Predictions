{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "# Amateur Hour - Predicting Stocks using LightGBM\n### Starter Kernel by ``Magichanics`` \n*([GitHub](https://github.com/Magichanics) - [Kaggle](https://www.kaggle.com/magichanics))*\n\nFeel free to post suggestions or criticisms!"
    },
    {
      "metadata": {
        "_uuid": "c6e9c58ee0984fd7aace750a5f542ceee09e17f0"
      },
      "cell_type": "markdown",
      "source": "## Table of Contents\n\n* [Step 1. Merging Datasets](#section1)\n* [Step 2. Feature Engineering](#section2)\n* [Step 3. Modelling using LightGBM](#section3)\n* [Step 4. Applying the Model](#section4)"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport os\nimport gc\nfrom itertools import chain\n\nimport matplotlib.pyplot as plt",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d9242e2e05ad6ae6897c99a33e224cc588621028",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# import environment for data\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Loading the data... This could take a minute.\nDone!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "451e7c9bd35702323a7df4db34b91921254a1369"
      },
      "cell_type": "code",
      "source": "(market_train_df, news_train_df) = env.get_training_data()\nsampling = True\nif sampling:\n    market_train_df = market_train_df.tail(400_000)\n    news_train_df = news_train_df.tail(1_000_000)",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a58dabdb861587a6dc5d2917ecc742727f3d1e60"
      },
      "cell_type": "markdown",
      "source": "<a id='section1'></a>\n## Step 1. Merging Datasets\n\nWhile most of the notebooks focuses only on the market dataset, I'm going to attempt on bringing both the news and market dataset together."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98ddae667a406f38302133fe776106f15e873eca",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "market_train_df.head()",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "                             time   ...    universe\n3672956 2016-02-19 22:00:00+00:00   ...         1.0\n3672957 2016-02-19 22:00:00+00:00   ...         0.0\n3672958 2016-02-19 22:00:00+00:00   ...         1.0\n3672959 2016-02-19 22:00:00+00:00   ...         1.0\n3672960 2016-02-19 22:00:00+00:00   ...         1.0\n\n[5 rows x 16 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>assetCode</th>\n      <th>assetName</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw1</th>\n      <th>returnsOpenPrevRaw1</th>\n      <th>returnsClosePrevMktres1</th>\n      <th>returnsOpenPrevMktres1</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n      <th>universe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3672956</th>\n      <td>2016-02-19 22:00:00+00:00</td>\n      <td>SPWR.O</td>\n      <td>SunPower Corp</td>\n      <td>4109129.0</td>\n      <td>21.14</td>\n      <td>22.25</td>\n      <td>-0.074431</td>\n      <td>-0.094055</td>\n      <td>-0.074354</td>\n      <td>-0.081761</td>\n      <td>-0.175828</td>\n      <td>-0.102823</td>\n      <td>-0.180055</td>\n      <td>-0.111746</td>\n      <td>0.068726</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3672957</th>\n      <td>2016-02-19 22:00:00+00:00</td>\n      <td>SQM.N</td>\n      <td>Sociedad Quimica y Minera de Chile SA</td>\n      <td>414021.0</td>\n      <td>17.15</td>\n      <td>16.94</td>\n      <td>0.002924</td>\n      <td>-0.033105</td>\n      <td>0.002975</td>\n      <td>-0.025269</td>\n      <td>0.051502</td>\n      <td>0.057428</td>\n      <td>0.049969</td>\n      <td>0.054736</td>\n      <td>-0.003696</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3672958</th>\n      <td>2016-02-19 22:00:00+00:00</td>\n      <td>SRC.N</td>\n      <td>Spirit Realty Capital Inc</td>\n      <td>7481287.0</td>\n      <td>11.09</td>\n      <td>11.09</td>\n      <td>-0.001800</td>\n      <td>0.024954</td>\n      <td>-0.001777</td>\n      <td>0.029012</td>\n      <td>0.038390</td>\n      <td>0.052182</td>\n      <td>0.035912</td>\n      <td>0.046627</td>\n      <td>-0.067333</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3672959</th>\n      <td>2016-02-19 22:00:00+00:00</td>\n      <td>SRCL.O</td>\n      <td>Stericycle Inc</td>\n      <td>898932.0</td>\n      <td>109.66</td>\n      <td>111.30</td>\n      <td>-0.016855</td>\n      <td>0.004241</td>\n      <td>-0.016824</td>\n      <td>0.008331</td>\n      <td>-0.054166</td>\n      <td>-0.052121</td>\n      <td>-0.055767</td>\n      <td>-0.054056</td>\n      <td>-0.044206</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3672960</th>\n      <td>2016-02-19 22:00:00+00:00</td>\n      <td>SRE.N</td>\n      <td>Sempra Energy</td>\n      <td>2143306.0</td>\n      <td>97.25</td>\n      <td>96.66</td>\n      <td>0.003819</td>\n      <td>0.014058</td>\n      <td>0.003833</td>\n      <td>0.015573</td>\n      <td>0.020355</td>\n      <td>0.012359</td>\n      <td>0.019882</td>\n      <td>0.011141</td>\n      <td>-0.006034</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3573a5f315d0fad58e8102d3a80d1f8cb269f8b7"
      },
      "cell_type": "code",
      "source": "news_train_df.head()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "                             time      ...       volumeCounts7D\n8328750 2015-12-08 13:56:53+00:00      ...                   63\n8328751 2015-12-08 13:57:20+00:00      ...                  167\n8328752 2015-12-08 13:57:20+00:00      ...                  166\n8328753 2015-12-08 13:57:37+00:00      ...                   10\n8328754 2015-12-08 13:57:41+00:00      ...                   17\n\n[5 rows x 35 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>sourceTimestamp</th>\n      <th>firstCreated</th>\n      <th>sourceId</th>\n      <th>headline</th>\n      <th>urgency</th>\n      <th>takeSequence</th>\n      <th>provider</th>\n      <th>subjects</th>\n      <th>audiences</th>\n      <th>bodySize</th>\n      <th>companyCount</th>\n      <th>headlineTag</th>\n      <th>marketCommentary</th>\n      <th>sentenceCount</th>\n      <th>wordCount</th>\n      <th>assetCodes</th>\n      <th>assetName</th>\n      <th>firstMentionSentence</th>\n      <th>relevance</th>\n      <th>sentimentClass</th>\n      <th>sentimentNegative</th>\n      <th>sentimentNeutral</th>\n      <th>sentimentPositive</th>\n      <th>sentimentWordCount</th>\n      <th>noveltyCount12H</th>\n      <th>noveltyCount24H</th>\n      <th>noveltyCount3D</th>\n      <th>noveltyCount5D</th>\n      <th>noveltyCount7D</th>\n      <th>volumeCounts12H</th>\n      <th>volumeCounts24H</th>\n      <th>volumeCounts3D</th>\n      <th>volumeCounts5D</th>\n      <th>volumeCounts7D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8328750</th>\n      <td>2015-12-08 13:56:53+00:00</td>\n      <td>2015-12-08 13:56:53+00:00</td>\n      <td>2015-12-08 13:56:53+00:00</td>\n      <td>f9c4067a6d20f21b</td>\n      <td>CHESAPEAKE ENERGY CORP SHARES EXTEND LOSSES, N...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'BLR', 'STX', 'OILG', 'EXPL', 'HOT', 'ENER', ...</td>\n      <td>{'E', 'U'}</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>2</td>\n      <td>21</td>\n      <td>{'CHK.N'}</td>\n      <td>Chesapeake Energy Corp</td>\n      <td>1</td>\n      <td>1.00000</td>\n      <td>-1</td>\n      <td>0.819143</td>\n      <td>0.125228</td>\n      <td>0.055629</td>\n      <td>21</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>7</td>\n      <td>9</td>\n      <td>17</td>\n      <td>23</td>\n      <td>24</td>\n      <td>41</td>\n      <td>63</td>\n    </tr>\n    <tr>\n      <th>8328751</th>\n      <td>2015-12-08 13:57:20+00:00</td>\n      <td>2015-12-08 13:57:20+00:00</td>\n      <td>2015-12-08 13:57:20+00:00</td>\n      <td>749e57557c589fca</td>\n      <td>REG - Societe Generale SA Anheuser-Busch InBev...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>LSE</td>\n      <td>{'NEWR', 'FOBE', 'WEU', 'BEVS', 'NCYC', 'LEN',...</td>\n      <td>{'LSEN'}</td>\n      <td>21427</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>47</td>\n      <td>1528</td>\n      <td>{'ABI.BR', 'BUD.N'}</td>\n      <td>Anheuser Busch Inbev SA</td>\n      <td>1</td>\n      <td>1.00000</td>\n      <td>0</td>\n      <td>0.014524</td>\n      <td>0.801992</td>\n      <td>0.183484</td>\n      <td>62</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>22</td>\n      <td>30</td>\n      <td>51</td>\n      <td>90</td>\n      <td>167</td>\n    </tr>\n    <tr>\n      <th>8328752</th>\n      <td>2015-12-08 13:57:20+00:00</td>\n      <td>2015-12-08 13:57:19+00:00</td>\n      <td>2015-12-08 13:57:19+00:00</td>\n      <td>e61c180b2be5eb45</td>\n      <td>REG - Societe Generale SA Anheuser-Busch InBev...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>LSE</td>\n      <td>{'NEWR', 'FOBE', 'WEU', 'BEVS', 'NCYC', 'LEN',...</td>\n      <td>{'LSEN'}</td>\n      <td>59958</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>53</td>\n      <td>4563</td>\n      <td>{'ABI.BR', 'BUD.N'}</td>\n      <td>Anheuser Busch Inbev SA</td>\n      <td>1</td>\n      <td>1.00000</td>\n      <td>1</td>\n      <td>0.035002</td>\n      <td>0.161918</td>\n      <td>0.803080</td>\n      <td>176</td>\n      <td>19</td>\n      <td>25</td>\n      <td>46</td>\n      <td>74</td>\n      <td>133</td>\n      <td>21</td>\n      <td>29</td>\n      <td>50</td>\n      <td>89</td>\n      <td>166</td>\n    </tr>\n    <tr>\n      <th>8328753</th>\n      <td>2015-12-08 13:57:37+00:00</td>\n      <td>2015-12-08 13:57:37+00:00</td>\n      <td>2015-12-08 13:57:37+00:00</td>\n      <td>35e01becdbd06d17</td>\n      <td>IIROC Trade Resumption - BIP.PR.B &lt;BIP.N&gt;</td>\n      <td>3</td>\n      <td>1</td>\n      <td>CNW</td>\n      <td>{'NEWR', 'LEN', 'ELEU', 'FINS', 'US', 'DFIN', ...</td>\n      <td>{'CNR', 'CNW'}</td>\n      <td>753</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>8</td>\n      <td>137</td>\n      <td>{'BIP.N'}</td>\n      <td>Brookfield Infrastructure Partners LP</td>\n      <td>4</td>\n      <td>0.57735</td>\n      <td>-1</td>\n      <td>0.811987</td>\n      <td>0.129426</td>\n      <td>0.058586</td>\n      <td>87</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>8328754</th>\n      <td>2015-12-08 13:57:41+00:00</td>\n      <td>2015-12-08 13:57:41+00:00</td>\n      <td>2015-12-08 13:57:41+00:00</td>\n      <td>36a59986b3a81936</td>\n      <td>TRANSOCEAN'S U.S.-LISTED SHARES DOWN 2.41 PCT ...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'BLR', 'STX', 'WEU', 'HOT', 'CH', 'DRIL', 'EN...</td>\n      <td>{'E', 'U'}</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>1</td>\n      <td>14</td>\n      <td>{'RIG.N', 'RIGN.VX', 'RIGN.BN'}</td>\n      <td>Transocean Ltd</td>\n      <td>1</td>\n      <td>1.00000</td>\n      <td>-1</td>\n      <td>0.819123</td>\n      <td>0.125241</td>\n      <td>0.055637</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>14</td>\n      <td>17</td>\n      <td>17</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "39a5a4da7d833cd2e0c2a9de9f6f30c6ec10f922"
      },
      "cell_type": "markdown",
      "source": "### Getting rid of Data prior to 2009\nData from the Financial Crisis may not benefit this model."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c35fe1a86234868804664c40675a7a4468b48d70"
      },
      "cell_type": "code",
      "source": "from datetime import datetime, timedelta\nstart = datetime(2009, 1, 1, 0, 0, 0).date()\nmarket_train_df = market_train_df.loc[market_train_df['time'].dt.date >= start].reset_index(drop=True)\nnews_train_df = news_train_df.loc[news_train_df['time'].dt.date >= start].reset_index(drop=True)",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f41abc107bdef775535477c924c4ff591d298fbf"
      },
      "cell_type": "markdown",
      "source": "### Time difference between time and firstCreated\nMaybe the news isn't that urgent if there was a time difference between the two columns."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "db40e27033e7a0c25103c32c83d1e54223ee8459"
      },
      "cell_type": "code",
      "source": "# WIP, will work on it later on\ndef time_diff(news_df):\n    \n    news_df['num_publishing_diff_secs'] = news_df['time'] - news_df['firstCreated']\n    news_df['num_publishing_diff_secs'] = news_df['num_publishing_diff_secs'] / np.timedelta64(1, 's')\n    return news_df",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5532e82bb00bea0fee62a7b8fd1fc226f2fc348c"
      },
      "cell_type": "code",
      "source": "news_train_df = time_diff(news_train_df)",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "13f7b88ce7c3473340251903b17106af89e8e213"
      },
      "cell_type": "markdown",
      "source": "### Cleaning Data\nWe will be removing the rows with the following qualities:\n* Empty headlines\n* Repeat headlines\n* Urgency of 2\n* Null assetName"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b2a9a6a69a66557f69b30b5e27553a2ba15bc933"
      },
      "cell_type": "code",
      "source": "def clean_data(market_df, news_df, train=True):\n    \n    # get rid of invalid rows\n    news_df = news_df[news_df.headline != '']\n    news_df = news_df[news_df.urgency != 2]\n    \n    # remove duplicate headlines with the same assetCodes\n    news_df = news_df.drop_duplicates(subset=['assetCodes', 'headline'],keep='first')\n\n    return market_df, news_df",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5e814659d584d93fa399c07746d050ba5ca62b2e"
      },
      "cell_type": "code",
      "source": "market_train_df, news_train_df = clean_data(market_train_df, news_train_df, train=True)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "54ea9c0ee8287b5edc984a84c07030a0e106d6c8"
      },
      "cell_type": "code",
      "source": "news_train_df.shape",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "(869377, 36)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b4b177c09e0546499a260041b7fb604673813ccf"
      },
      "cell_type": "code",
      "source": "market_train_df.shape",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "(400000, 16)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "486d593869589819aefadb4345af1b5db0060ffc"
      },
      "cell_type": "markdown",
      "source": "### Expanding News data\nWe are going to be splitting the news data by assetCode."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "29b5aa276e3bfb61ae5a83dbb24162da1f0a72c6"
      },
      "cell_type": "code",
      "source": "def expanding_news(news_df):\n    \n    # split to list\n    news_output = news_df.copy()\n    news_output['assetCodes'] = news_output['assetCodes'].str.findall(f\"'([\\w\\./]+)'\")\n    \n    # separate to assetcodes\n    assetCodes_expanded = list(chain(*news_output['assetCodes']))\n    assetCodes_index = news_df.index.repeat(news_output['assetCodes'].apply(len))\n    assert len(assetCodes_index) == len(assetCodes_expanded)\n    df_assetCodes = pd.DataFrame({'level_0': assetCodes_index, 'assetCode': assetCodes_expanded})\n    \n    # merge to dataframe\n    merging_cols = [f for f in news_output if f not in ['assetCodes', 'sourceId']]\n    news_df_expanded = pd.merge(df_assetCodes, news_output[merging_cols], left_on='level_0', \n                                right_index=True, suffixes=(['','_old']))\n    \n    return news_df_expanded",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "783cae5ad82f345e1d620fcdf7b22e9c76fa3e29"
      },
      "cell_type": "code",
      "source": "expand_train_df = expanding_news(news_train_df)",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "368a6fd592fc50eeefa583123cb1b1fa7ad28dd3"
      },
      "cell_type": "code",
      "source": "expand_train_df.tail()",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "         level_0           ...            num_publishing_diff_secs\n1608941   999997           ...                                 0.0\n1608942   999997           ...                                 0.0\n1608943   999998           ...                                 0.0\n1608944   999998           ...                                 0.0\n1608945   999999           ...                                 0.0\n\n[5 rows x 36 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>assetCode</th>\n      <th>time</th>\n      <th>sourceTimestamp</th>\n      <th>firstCreated</th>\n      <th>headline</th>\n      <th>urgency</th>\n      <th>takeSequence</th>\n      <th>provider</th>\n      <th>subjects</th>\n      <th>audiences</th>\n      <th>bodySize</th>\n      <th>companyCount</th>\n      <th>headlineTag</th>\n      <th>marketCommentary</th>\n      <th>sentenceCount</th>\n      <th>wordCount</th>\n      <th>assetName</th>\n      <th>firstMentionSentence</th>\n      <th>relevance</th>\n      <th>sentimentClass</th>\n      <th>sentimentNegative</th>\n      <th>sentimentNeutral</th>\n      <th>sentimentPositive</th>\n      <th>sentimentWordCount</th>\n      <th>noveltyCount12H</th>\n      <th>noveltyCount24H</th>\n      <th>noveltyCount3D</th>\n      <th>noveltyCount5D</th>\n      <th>noveltyCount7D</th>\n      <th>volumeCounts12H</th>\n      <th>volumeCounts24H</th>\n      <th>volumeCounts3D</th>\n      <th>volumeCounts5D</th>\n      <th>volumeCounts7D</th>\n      <th>num_publishing_diff_secs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1608941</th>\n      <td>999997</td>\n      <td>SGEN.O</td>\n      <td>2016-12-30 21:57:00+00:00</td>\n      <td>2016-12-30 21:57:00+00:00</td>\n      <td>2016-12-30 21:57:00+00:00</td>\n      <td>EQUITY ALERT: Rosen Law Firm Announces Investi...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>BSW</td>\n      <td>{'CMSS', 'CLJ', 'GEN', 'NEWR', 'HECA', 'PHMR',...</td>\n      <td>{'BSW', 'CNR'}</td>\n      <td>3734</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>16</td>\n      <td>664</td>\n      <td>Seattle Genetics Inc</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>-1</td>\n      <td>0.651900</td>\n      <td>0.227707</td>\n      <td>0.120393</td>\n      <td>360</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>18</td>\n      <td>41</td>\n      <td>41</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1608942</th>\n      <td>999997</td>\n      <td>SGEN.OQ</td>\n      <td>2016-12-30 21:57:00+00:00</td>\n      <td>2016-12-30 21:57:00+00:00</td>\n      <td>2016-12-30 21:57:00+00:00</td>\n      <td>EQUITY ALERT: Rosen Law Firm Announces Investi...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>BSW</td>\n      <td>{'CMSS', 'CLJ', 'GEN', 'NEWR', 'HECA', 'PHMR',...</td>\n      <td>{'BSW', 'CNR'}</td>\n      <td>3734</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>16</td>\n      <td>664</td>\n      <td>Seattle Genetics Inc</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>-1</td>\n      <td>0.651900</td>\n      <td>0.227707</td>\n      <td>0.120393</td>\n      <td>360</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>18</td>\n      <td>41</td>\n      <td>41</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1608943</th>\n      <td>999998</td>\n      <td>IPDN.O</td>\n      <td>2016-12-30 21:58:53+00:00</td>\n      <td>2016-12-30 21:58:53+00:00</td>\n      <td>2016-12-30 21:58:53+00:00</td>\n      <td>PROFESSIONAL DIVERSITY NETWORK INC - FILES FOR...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'BLR', 'SWIT', 'ITSE', 'SISU', 'BACT', 'TMT',...</td>\n      <td>{'E', 'U'}</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>1</td>\n      <td>23</td>\n      <td>Professional Diversity Network Inc</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>-1</td>\n      <td>0.816252</td>\n      <td>0.126928</td>\n      <td>0.056819</td>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1608944</th>\n      <td>999998</td>\n      <td>IPDN.OQ</td>\n      <td>2016-12-30 21:58:53+00:00</td>\n      <td>2016-12-30 21:58:53+00:00</td>\n      <td>2016-12-30 21:58:53+00:00</td>\n      <td>PROFESSIONAL DIVERSITY NETWORK INC - FILES FOR...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'BLR', 'SWIT', 'ITSE', 'SISU', 'BACT', 'TMT',...</td>\n      <td>{'E', 'U'}</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>1</td>\n      <td>23</td>\n      <td>Professional Diversity Network Inc</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>-1</td>\n      <td>0.816252</td>\n      <td>0.126928</td>\n      <td>0.056819</td>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1608945</th>\n      <td>999999</td>\n      <td>JFC.N</td>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>JPMorgan China Region Fund, Inc. Board to Subm...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>BSW</td>\n      <td>{'CMSS', 'NEWR', 'INVT', 'BACT', 'BSUP', 'INDS...</td>\n      <td>{'BSW', 'CNR'}</td>\n      <td>2969</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>15</td>\n      <td>492</td>\n      <td>JPMorgan China Region Fund Inc</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.130152</td>\n      <td>0.388845</td>\n      <td>0.481002</td>\n      <td>383</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3e4b182a9fd045db6a0ef4941324471ef60496f6"
      },
      "cell_type": "code",
      "source": "market_train_df.tail()",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "                            time   ...    universe\n399995 2016-12-30 22:00:00+00:00   ...         0.0\n399996 2016-12-30 22:00:00+00:00   ...         0.0\n399997 2016-12-30 22:00:00+00:00   ...         0.0\n399998 2016-12-30 22:00:00+00:00   ...         1.0\n399999 2016-12-30 22:00:00+00:00   ...         1.0\n\n[5 rows x 16 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>assetCode</th>\n      <th>assetName</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw1</th>\n      <th>returnsOpenPrevRaw1</th>\n      <th>returnsClosePrevMktres1</th>\n      <th>returnsOpenPrevMktres1</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n      <th>universe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>399995</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZIOP.O</td>\n      <td>ZIOPHARM Oncology Inc</td>\n      <td>1608829.0</td>\n      <td>5.35</td>\n      <td>5.37</td>\n      <td>-0.003724</td>\n      <td>0.000000</td>\n      <td>0.000536</td>\n      <td>-0.001868</td>\n      <td>-0.165367</td>\n      <td>-0.138042</td>\n      <td>-0.139597</td>\n      <td>-0.135913</td>\n      <td>0.051189</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>399996</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZLTQ.O</td>\n      <td>ZELTIQ Aesthetics Inc</td>\n      <td>347830.0</td>\n      <td>43.52</td>\n      <td>43.62</td>\n      <td>-0.000689</td>\n      <td>0.000000</td>\n      <td>-0.000515</td>\n      <td>0.000493</td>\n      <td>0.002996</td>\n      <td>0.002989</td>\n      <td>0.008213</td>\n      <td>0.003210</td>\n      <td>-0.048555</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>399997</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZNGA.O</td>\n      <td>Zynga Inc</td>\n      <td>7396601.0</td>\n      <td>2.57</td>\n      <td>2.58</td>\n      <td>-0.011538</td>\n      <td>0.000000</td>\n      <td>-0.006004</td>\n      <td>-0.001034</td>\n      <td>-0.091873</td>\n      <td>-0.078571</td>\n      <td>-0.077252</td>\n      <td>-0.077188</td>\n      <td>0.011703</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>399998</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZTO.N</td>\n      <td>Unknown</td>\n      <td>3146519.0</td>\n      <td>12.07</td>\n      <td>12.50</td>\n      <td>-0.029743</td>\n      <td>0.007252</td>\n      <td>-0.028460</td>\n      <td>0.006719</td>\n      <td>-0.065066</td>\n      <td>-0.042146</td>\n      <td>-0.078104</td>\n      <td>-0.043813</td>\n      <td>0.083367</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>399999</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZTS.N</td>\n      <td>Zoetis Inc</td>\n      <td>1701204.0</td>\n      <td>53.53</td>\n      <td>53.64</td>\n      <td>-0.001678</td>\n      <td>0.003091</td>\n      <td>0.005060</td>\n      <td>0.002885</td>\n      <td>0.023127</td>\n      <td>0.028177</td>\n      <td>0.026566</td>\n      <td>0.028719</td>\n      <td>-0.016220</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "e2c2e63e365f4b89f660f17ffbeb38545a0c05db"
      },
      "cell_type": "markdown",
      "source": "### Cleaning Headlines\nThe following will simplify strings to only get the necessary words needed for text processing."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e8e89a5e3cfd230ee137cf88be5f557765243d5e"
      },
      "cell_type": "code",
      "source": "from nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport re\n\nps = PorterStemmer()\nsw = stopwords.words('english')\n\n# this takes up a lot of time, so apply it when getting coefficients to filter out words.\ndef clean_headlines(headline):\n    \n    # remove numerical and convert to lowercase\n    headline =  re.sub('[^a-zA-Z]',' ',headline)\n    headline = headline.lower()\n    \n    # use stemming to simplify words\n    headline_words_rough = headline.split(' ')\n    \n    # check if stopwords are present in headlines\n    headline_words = []\n    for word in headline_words_rough:\n        if word not in sw:\n            # use stemming to simplify\n            headline_words.append(ps.stem(word))\n    \n    # join sentence back again\n    return ' '.join(headline_words)",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c90a1d3d5da39a17a36b06a756470ff6dee6d53b"
      },
      "cell_type": "markdown",
      "source": "### Categorical Groupby\nThis will merge groups of categorical data together into either lists or sets."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "27a4e721de05191399c01e8724a39022d0f1b77e"
      },
      "cell_type": "code",
      "source": "def categorical_groupby(expand_df):\n\n    # get categorical groupbys\n    main_cols = ['time', 'assetCode']\n    expand_headline_groupby = expand_df[main_cols + ['headline']].groupby(['time', 'assetCode'])\n    expand_cat_groupby = expand_df[main_cols + ['subjects', 'audiences']].groupby(['time', 'assetCode'])\n    \n    # split subjects and audiences\n    def cat_to_list(x):\n        if x.name not in ['time', 'assetCode'] and x.name != 'headline':\n            result = []\n            for item in x:\n                result += item\n            return list(set(result)) # returns unique audiences/subjects\n        elif x.name == 'headline':\n            return list(x)\n    \n    # convert groupby to dataframes\n    expand_cat_df = expand_cat_groupby.transform(lambda x: cat_to_list(x))\n    expand_headline_df = expand_headline_groupby.transform(lambda x: cat_to_list(x)) # can't iterate through?\n\n    # merge to categorical dataframes\n    return pd.concat([expand_cat_df, expand_headline_df], axis=1)\n    ",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a0f32a0c7e865a495e93cb7d0144aadfa5eddda2"
      },
      "cell_type": "markdown",
      "source": "### Numerical Groupby\nThis will merge groups of numerical data together through aggregating the data."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "02bbfecae766db4df6b63c24b49c2c294f9fab96"
      },
      "cell_type": "code",
      "source": "# get aggregated columns + aggregation map\nnews_agg_cols = [f for f in news_train_df.columns if 'novelty' in f or\n                'volume' in f or\n                'sentiment' in f or\n                'bodySize' in f or\n                'Count' in f or\n                'marketCommentary' in f or\n                'relevance' in f or\n                'num_' in f]\nnews_agg_dict = {}\nfor col in news_agg_cols:\n    news_agg_dict[col] = ['mean']\nnews_agg_dict['urgency'] = ['min', 'count']\nnews_agg_dict['takeSequence'] = ['max']\n    \ndef numerical_groupby(expand_df):\n    \n    # aggregate dataframe\n    expand_agg_groupby = expand_df[['time', 'assetCode'] + sorted(list(news_agg_dict.keys()))].groupby(['time', 'assetCode'])\n    expand_agg_df = expand_agg_groupby.agg(news_agg_dict).apply(np.float32)\n    expand_agg_df.columns = ['_'.join(col).strip() for col in expand_agg_df.columns.values]\n    \n    return expand_agg_df",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5538d778f93b8193ec36ef8c11d6ac0ea3f305a0"
      },
      "cell_type": "markdown",
      "source": "### Merge by time &  assetCode to News Article\nWe will be merging rows with the same time and assetCode."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1653c7e20b8d9bcd4541c2f7da29549d3b1f7f2b"
      },
      "cell_type": "code",
      "source": "def get_matches(market_df, expand_df):\n    \n    # get temporary columns as data\n    temp_market_df = market_df[['time', 'assetCode']].copy()\n    temp_expand_df = expand_df[['time', 'assetCode']].copy()\n    \n    # get indecies\n    temp_expand_df['expand_index'] = temp_expand_df.index.values\n    \n    # join the two\n    temp_expand_df.set_index(['time', 'assetCode'], inplace=True)\n    temp_expand_market_df = temp_market_df.join(temp_expand_df, on=['time', 'assetCode'])\n    \n    # remove nulls\n    temp_expand_market_df = temp_expand_market_df[temp_expand_market_df.expand_index.isnull() == False]\n    expand_indicies = temp_expand_market_df['expand_index'].tolist()\n    \n    # do final cleanup\n    del temp_market_df\n    del temp_expand_df\n    \n    # fetch matches\n    return expand_df.loc[expand_indicies]\n\ndef merge_by_code(market_df, expand_df):\n    \n    # use a copy\n    market_df_copy = market_df.copy()\n    \n    # get expansion of rows\n    expand_df = get_matches(market_df, expand_df)\n    \n    # convert to lists\n    expand_df['subjects'] = expand_df['subjects'].str.findall(f\"'([\\w\\./]+)'\")\n    expand_df['audiences'] = expand_df['audiences'].str.findall(f\"'([\\w\\./]+)'\")\n    \n    # clean headlines\n    expand_df['headline'] = expand_df['headline'].apply(clean_headlines)\n    \n    # group categoricals\n    expand_cat_df = categorical_groupby(expand_df)\n    expand_cat_df['time'] = expand_df['time']\n    expand_cat_df['assetCode'] = expand_df['assetCode']\n    \n    # convert to sets\n    for cat_col in ['subjects', 'audiences']:\n        expand_cat_df[cat_col] = expand_cat_df[cat_col].apply(tuple)\n        \n    # remove duplicate rows\n    expand_cat_df = expand_cat_df.drop_duplicates(subset=['time', 'assetCode'],\n                                                  keep='first')\n\n    # group numericals\n    expand_num_df = numerical_groupby(expand_df)\n    \n    # merge datasets\n    expanded_market_df = expand_cat_df.join(expand_num_df, on=['time', 'assetCode'])\n    expanded_market_df = pd.merge(market_df_copy, expanded_market_df, \n                                  on=['time', 'assetCode'], how='left')\n    \n    return expanded_market_df\n    ",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9d57e35717560cdafdc3101450cf48d793492ab9"
      },
      "cell_type": "code",
      "source": "%%time\nX_train = merge_by_code(market_train_df, expand_train_df)",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": "CPU times: user 21.4 s, sys: 7.2 s, total: 28.6 s\nWall time: 28.5 s\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eff9fd44d08967c5719fc2151dc77e2c945aac00"
      },
      "cell_type": "code",
      "source": "X_train.tail()",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "                            time       ...        takeSequence_max\n399995 2016-12-30 22:00:00+00:00       ...                     NaN\n399996 2016-12-30 22:00:00+00:00       ...                     NaN\n399997 2016-12-30 22:00:00+00:00       ...                     NaN\n399998 2016-12-30 22:00:00+00:00       ...                     NaN\n399999 2016-12-30 22:00:00+00:00       ...                     NaN\n\n[5 rows x 44 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>assetCode</th>\n      <th>assetName</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw1</th>\n      <th>returnsOpenPrevRaw1</th>\n      <th>returnsClosePrevMktres1</th>\n      <th>returnsOpenPrevMktres1</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n      <th>universe</th>\n      <th>subjects</th>\n      <th>audiences</th>\n      <th>headline</th>\n      <th>bodySize_mean</th>\n      <th>companyCount_mean</th>\n      <th>marketCommentary_mean</th>\n      <th>sentenceCount_mean</th>\n      <th>wordCount_mean</th>\n      <th>relevance_mean</th>\n      <th>sentimentClass_mean</th>\n      <th>sentimentNegative_mean</th>\n      <th>sentimentNeutral_mean</th>\n      <th>sentimentPositive_mean</th>\n      <th>sentimentWordCount_mean</th>\n      <th>noveltyCount12H_mean</th>\n      <th>noveltyCount24H_mean</th>\n      <th>noveltyCount3D_mean</th>\n      <th>noveltyCount5D_mean</th>\n      <th>noveltyCount7D_mean</th>\n      <th>volumeCounts12H_mean</th>\n      <th>volumeCounts24H_mean</th>\n      <th>volumeCounts3D_mean</th>\n      <th>volumeCounts5D_mean</th>\n      <th>volumeCounts7D_mean</th>\n      <th>num_publishing_diff_secs_mean</th>\n      <th>urgency_min</th>\n      <th>urgency_count</th>\n      <th>takeSequence_max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>399995</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZIOP.O</td>\n      <td>ZIOPHARM Oncology Inc</td>\n      <td>1608829.0</td>\n      <td>5.35</td>\n      <td>5.37</td>\n      <td>-0.003724</td>\n      <td>0.000000</td>\n      <td>0.000536</td>\n      <td>-0.001868</td>\n      <td>-0.165367</td>\n      <td>-0.138042</td>\n      <td>-0.139597</td>\n      <td>-0.135913</td>\n      <td>0.051189</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>399996</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZLTQ.O</td>\n      <td>ZELTIQ Aesthetics Inc</td>\n      <td>347830.0</td>\n      <td>43.52</td>\n      <td>43.62</td>\n      <td>-0.000689</td>\n      <td>0.000000</td>\n      <td>-0.000515</td>\n      <td>0.000493</td>\n      <td>0.002996</td>\n      <td>0.002989</td>\n      <td>0.008213</td>\n      <td>0.003210</td>\n      <td>-0.048555</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>399997</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZNGA.O</td>\n      <td>Zynga Inc</td>\n      <td>7396601.0</td>\n      <td>2.57</td>\n      <td>2.58</td>\n      <td>-0.011538</td>\n      <td>0.000000</td>\n      <td>-0.006004</td>\n      <td>-0.001034</td>\n      <td>-0.091873</td>\n      <td>-0.078571</td>\n      <td>-0.077252</td>\n      <td>-0.077188</td>\n      <td>0.011703</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>399998</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZTO.N</td>\n      <td>Unknown</td>\n      <td>3146519.0</td>\n      <td>12.07</td>\n      <td>12.50</td>\n      <td>-0.029743</td>\n      <td>0.007252</td>\n      <td>-0.028460</td>\n      <td>0.006719</td>\n      <td>-0.065066</td>\n      <td>-0.042146</td>\n      <td>-0.078104</td>\n      <td>-0.043813</td>\n      <td>0.083367</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>399999</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZTS.N</td>\n      <td>Zoetis Inc</td>\n      <td>1701204.0</td>\n      <td>53.53</td>\n      <td>53.64</td>\n      <td>-0.001678</td>\n      <td>0.003091</td>\n      <td>0.005060</td>\n      <td>0.002885</td>\n      <td>0.023127</td>\n      <td>0.028177</td>\n      <td>0.026566</td>\n      <td>0.028719</td>\n      <td>-0.016220</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c6e0cb4a4a1afdf47dd0501b41b62107d2fa7fe4"
      },
      "cell_type": "code",
      "source": "def data_step1(market_test_df, news_test_df):\n    \n    news_test_df = time_diff(news_test_df)\n    market_test_df, news_test_df = clean_data(market_test_df, news_test_df, train=False)\n    expand_test_df = expanding_news(news_test_df)\n    X_test = merge_by_code(market_test_df, expand_test_df)\n    \n    return X_test\n    ",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "85264b01227975ac181afc1b2bb4c989d704f290"
      },
      "cell_type": "markdown",
      "source": "Step 1 with the Full dataset: \n\n* CPU times: user 38.1 s, sys: 9.73 s, total: 47.8 s\n\n* Wall time: 47.8 s\n\nCompared to [Amateur Hour's](https://www.kaggle.com/magichanics/amateur-hour-using-headlines-to-predict-stocks) method of merging datasets, this one preforms the merge a lot faster."
    },
    {
      "metadata": {
        "_uuid": "b24a1eb7424ef10af9dbb4ee7c177dfefa220f51"
      },
      "cell_type": "markdown",
      "source": "<a id='section2'></a>\n## Step 2. Feature Engineering\n\nFrom Quant features to text processing features."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "434e633c799d075f6dcc14e6d00104b5cafbe0b4"
      },
      "cell_type": "code",
      "source": "X_train.tail()",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "                            time       ...        takeSequence_max\n399995 2016-12-30 22:00:00+00:00       ...                     NaN\n399996 2016-12-30 22:00:00+00:00       ...                     NaN\n399997 2016-12-30 22:00:00+00:00       ...                     NaN\n399998 2016-12-30 22:00:00+00:00       ...                     NaN\n399999 2016-12-30 22:00:00+00:00       ...                     NaN\n\n[5 rows x 44 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>assetCode</th>\n      <th>assetName</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw1</th>\n      <th>returnsOpenPrevRaw1</th>\n      <th>returnsClosePrevMktres1</th>\n      <th>returnsOpenPrevMktres1</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n      <th>universe</th>\n      <th>subjects</th>\n      <th>audiences</th>\n      <th>headline</th>\n      <th>bodySize_mean</th>\n      <th>companyCount_mean</th>\n      <th>marketCommentary_mean</th>\n      <th>sentenceCount_mean</th>\n      <th>wordCount_mean</th>\n      <th>relevance_mean</th>\n      <th>sentimentClass_mean</th>\n      <th>sentimentNegative_mean</th>\n      <th>sentimentNeutral_mean</th>\n      <th>sentimentPositive_mean</th>\n      <th>sentimentWordCount_mean</th>\n      <th>noveltyCount12H_mean</th>\n      <th>noveltyCount24H_mean</th>\n      <th>noveltyCount3D_mean</th>\n      <th>noveltyCount5D_mean</th>\n      <th>noveltyCount7D_mean</th>\n      <th>volumeCounts12H_mean</th>\n      <th>volumeCounts24H_mean</th>\n      <th>volumeCounts3D_mean</th>\n      <th>volumeCounts5D_mean</th>\n      <th>volumeCounts7D_mean</th>\n      <th>num_publishing_diff_secs_mean</th>\n      <th>urgency_min</th>\n      <th>urgency_count</th>\n      <th>takeSequence_max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>399995</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZIOP.O</td>\n      <td>ZIOPHARM Oncology Inc</td>\n      <td>1608829.0</td>\n      <td>5.35</td>\n      <td>5.37</td>\n      <td>-0.003724</td>\n      <td>0.000000</td>\n      <td>0.000536</td>\n      <td>-0.001868</td>\n      <td>-0.165367</td>\n      <td>-0.138042</td>\n      <td>-0.139597</td>\n      <td>-0.135913</td>\n      <td>0.051189</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>399996</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZLTQ.O</td>\n      <td>ZELTIQ Aesthetics Inc</td>\n      <td>347830.0</td>\n      <td>43.52</td>\n      <td>43.62</td>\n      <td>-0.000689</td>\n      <td>0.000000</td>\n      <td>-0.000515</td>\n      <td>0.000493</td>\n      <td>0.002996</td>\n      <td>0.002989</td>\n      <td>0.008213</td>\n      <td>0.003210</td>\n      <td>-0.048555</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>399997</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZNGA.O</td>\n      <td>Zynga Inc</td>\n      <td>7396601.0</td>\n      <td>2.57</td>\n      <td>2.58</td>\n      <td>-0.011538</td>\n      <td>0.000000</td>\n      <td>-0.006004</td>\n      <td>-0.001034</td>\n      <td>-0.091873</td>\n      <td>-0.078571</td>\n      <td>-0.077252</td>\n      <td>-0.077188</td>\n      <td>0.011703</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>399998</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZTO.N</td>\n      <td>Unknown</td>\n      <td>3146519.0</td>\n      <td>12.07</td>\n      <td>12.50</td>\n      <td>-0.029743</td>\n      <td>0.007252</td>\n      <td>-0.028460</td>\n      <td>0.006719</td>\n      <td>-0.065066</td>\n      <td>-0.042146</td>\n      <td>-0.078104</td>\n      <td>-0.043813</td>\n      <td>0.083367</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>399999</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZTS.N</td>\n      <td>Zoetis Inc</td>\n      <td>1701204.0</td>\n      <td>53.53</td>\n      <td>53.64</td>\n      <td>-0.001678</td>\n      <td>0.003091</td>\n      <td>0.005060</td>\n      <td>0.002885</td>\n      <td>0.023127</td>\n      <td>0.028177</td>\n      <td>0.026566</td>\n      <td>0.028719</td>\n      <td>-0.016220</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "bc65f763ab467376a231e0e96f4d2f98747e22c9"
      },
      "cell_type": "markdown",
      "source": "### Entire Market and Individual Asset Quant Features\nWe are going to be obtaining Quant Features from both the entire market dataframe and from each individual asset based on assetCode."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e342e97472e169d5aff79f38181a2c936c70f04b"
      },
      "cell_type": "code",
      "source": "def quant_feats(X):\n    \n    def moving_average(X_MA, columns, str_type):\n        \n        windows = [3, 7, 14]\n        \n        for col in columns:\n            \n            for window in windows:\n                \n                roll_col = X_MA[col].rolling(window=window)\n                X_MA['%s_%s_%sMA'%(str_type, col, window)] = roll_col.mean()\n                X_MA['%s_%s_%sSTD'%(str_type, col, window)] = roll_col.std()\n                X_MA['%s_%s_%sMAX'%(str_type, col, window)] = roll_col.max()\n                X_MA['%s_%s_%sMIN'%(str_type, col, window)] = roll_col.min()\n        \n        # convert to float32\n        return X_MA\n    \n    # get std and moving average of the entire dataset\n    X = moving_average(X, columns=['close', 'volume'], str_type='global')\n    \n    print('finished global')\n    \n    # get std and moving average of each individual asset based on assetCode\n    iterations = 0\n    for asset in X['assetCode'].unique():\n        \n        # get indices (faster)\n        asset_indices = X[X.assetCode == asset].index.values\n        \n        # get std and ma\n        X.loc[asset_indices] = moving_average(X.loc[asset_indices], columns=['close', 'volume'], str_type='asset')\n        \n        # display iterations\n        if iterations % 250 == 0:\n            print('On asset: ' + str(iterations) + ' of ' + str(len(X['assetCode'].unique())))\n        iterations += 1\n        \n    return X",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bbaa035edb76d6d07eb53f82366e7c584a347f7a"
      },
      "cell_type": "markdown",
      "source": "``market_train_df = market_train_df.tail(400_000)\nnews_train_df = news_train_df.tail(1_000_000)``\n* CPU times: user 10min 51s, sys: 76 ms, total: 10min 52s\n* Wall time: 10min 52s"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f9f9631af780ad05c2431fe09cb469dbcee38548"
      },
      "cell_type": "code",
      "source": "%%time\nX_train = quant_feats(X_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "26fb740a713963d533d1cb9684b81a3f6795525a"
      },
      "cell_type": "markdown",
      "source": "### Text Processing with CountVectorizer\nWe are going to be using CountVectorizer on headlines, audiences and subjects to determine its influence on the target column."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "47ec4db7796b018c4991b5220a4bfeee5c4885d7",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\n\nclass TextToCoeff:\n\n    def vectorize(self, X_):\n\n        # get required dataset\n        X_text = X_.copy()[['returnsOpenNextMktres10', self.col]].dropna()\n\n        # round data (if objective : binary)\n        def round_scores(x):\n            if x >= 0:\n                return 1\n            else:\n                return 0\n        X_text['returnsOpenNextMktres10'] = X_text['returnsOpenNextMktres10'].apply(round_scores)\n\n        # convert tuples to string format if applicable\n        def tuple_to_str(x):\n            if isinstance(x, tuple):\n                return ' '.join(x)\n            else:\n                return x\n        X_text[self.col] = X_text[self.col].apply(tuple_to_str)\n\n        # get lists\n        text_lst = list(X_text[self.col])\n        target_lst = list(X_text['returnsOpenNextMktres10'])\n\n        # vectorize text features\n        vectorizer = CountVectorizer()\n        text_vectorized = vectorizer.fit_transform(text_lst)\n\n        # model data (will use other modelling methods in the future)\n        text_model = LogisticRegression()\n        text_model = text_model.fit(text_vectorized, target_lst)\n\n        # get coefficients\n        basictext = vectorizer.get_feature_names()\n        basiccoeffs = text_model.coef_.tolist()[0]\n        coeff_df = pd.DataFrame({'Text' : basictext, \n                                'Coefficient' : basiccoeffs})\n\n        # convert dataframe to dictionary of coefficients\n        self.coeff_dict = dict(zip(coeff_df.Text, coeff_df.Coefficient))\n\n        # get value that accounts for nulls\n        self.coeff_default = coeff_df['Coefficient'].mean()\n\n    def predict_data(self, X_):\n\n        def get_coeff(x):\n            \n            try:\n\n                # iterate through each set of text data\n                coeff_total_score = 0\n                \n                if isinstance(x, tuple):\n                    x = ' '.join(x)\n                    \n                if isinstance(x, str):\n                    x = [x]\n                \n                for textset in x:\n\n                    text_lst = textset.split(' ')\n                \n                    # iter through every word\n                    coeff_sum = 0\n                    for text in text_lst:\n                        text = text.lower()\n                        if text in self.coeff_dict:\n                            coeff_sum += self.coeff_dict[text]\n                        else:\n                            coeff_sum += self.coeff_default\n\n                    # get average coefficient\n                    coeff_total_score += coeff_sum / len(text_lst)\n\n                return coeff_total_score / len(x)\n            \n            except TypeError:\n                \n                return np.nan\n\n        X_[self.col + '_coeff_mean'] = X_[self.col].apply(get_coeff)\n        \n        return X_\n\n    # obtain target volumn\n    def __init__(self, input_col):\n        self.col = input_col",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "90878febb77aa9c2a14f420fedc3a8763e019e4e"
      },
      "cell_type": "code",
      "source": "def text_processing_train(X):\n    \n    # get list of text to coeff converters [headline, subjects, audiences]\n    text_to_coeff_lst = []\n    for f in ['headline', 'subjects', 'audiences']:\n        text_to_coeff = TextToCoeff(f)\n        text_to_coeff.vectorize(X)\n        text_to_coeff_lst.append(text_to_coeff)\n    \n    return text_to_coeff_lst\n\ndef text_processing_test(X, text_to_coeff_lst):\n    \n    for text_to_coeff in text_to_coeff_lst:\n        X = text_to_coeff.predict_data(X)\n    \n    return X",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ce0e7f1799a9199300876768e5e758688628dbbb"
      },
      "cell_type": "code",
      "source": "%%time\ntext_to_coeff_lst = text_processing_train(X_train)\nX_train = text_processing_test(X_train, text_to_coeff_lst)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ee95784fb1993f7f76453efc7714a23fb6e83f9a"
      },
      "cell_type": "markdown",
      "source": "### Clustering\nWe will be clustering the open and close features using KMeans."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "85c1e43b0e3d2b082a3e2badb0c13da2f3b0562c"
      },
      "cell_type": "code",
      "source": "from sklearn.cluster import KMeans\n\ndef clustering(X):\n\n    def cluster_modelling(features):\n        df_set = X[features]\n        cluster_model = KMeans(n_clusters = 8)\n        cluster_model.fit(df_set)\n        return cluster_model.predict(df_set)\n    \n    # get columns:\n    vol_cols = [f for f in X.columns if f != 'volume' and 'volume' in f]\n    novelty_cols = [f for f in X.columns if 'novelty' in f]\n    \n    # fill nulls\n    cluster_cols = novelty_cols + vol_cols + ['open', 'close']\n    X[cluster_cols] = X[cluster_cols].fillna(0)\n    \n    X['cluster_open_close'] = cluster_modelling(['open', 'close'])\n    X['cluster_volume'] = cluster_modelling(vol_cols)\n    X['cluster_novelty'] = cluster_modelling(novelty_cols)\n    \n    return X",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4da114e64381b829639cfceac5c69c0d96f2999e"
      },
      "cell_type": "code",
      "source": "X_train = clustering(X_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bc5e1e76b0da8d54944b2f052a260c6262b0c14b"
      },
      "cell_type": "markdown",
      "source": "### Misc. Features\nInclues the following features:\n* Daily Difference"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "efb62b12fc7e92dc4ca1047faa85e796b33f2847"
      },
      "cell_type": "code",
      "source": "def misc_features(X):\n    \n    # Adding daily difference\n    new_col = X[\"close\"] - X[\"open\"]\n    X.insert(loc=6, column=\"daily_diff\", value=new_col)\n    X['close_to_open'] =  np.abs(X['close'] / X['open'])\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "522167cbd0bff9410e5fdab6b4b7ccabbef85b73"
      },
      "cell_type": "code",
      "source": "misc_features(X_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a43e6531abec41d694afed23ddb3c34ea113bda5"
      },
      "cell_type": "code",
      "source": "X_train.dropna().tail()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e77a7f29b9e43a9b81f4d61c71f83a5b3470f097"
      },
      "cell_type": "code",
      "source": "del market_train_df, news_train_df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9a69dad5e4480701ff63f383d1d12c395fe8493c"
      },
      "cell_type": "code",
      "source": "def data_step2(X_test):\n    \n    X_test = quant_feats(X_test)\n    X_test = text_processing_test(X_test, text_to_coeff_lst)\n    X_test = clustering(X_test)\n    misc_features(X_test)\n    \n    return X_test",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ab3199b41454b6093f0cd2be4dddf3b869824596"
      },
      "cell_type": "markdown",
      "source": "<a id='section3'></a>\n## Step 3. Modelling using LightGBM"
    },
    {
      "metadata": {
        "_uuid": "5853a3b60388bbab1fcd48a0d98d446d0f3d5826"
      },
      "cell_type": "markdown",
      "source": "### Preparing Datasets for Modelling"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "64fd6fa8dddce53665260f06c7c828625105fe95"
      },
      "cell_type": "code",
      "source": "y_train = X_train['returnsOpenNextMktres10']\nX_train = X_train[[f for f in X_train.columns if f not in ['time', 'assetCode', 'universe', 'assetName', 'returnsOpenNextMktres10',\n                                                          'headline', 'subjects', 'audiences']]].fillna(0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "76abdc01a2846fe429c2364a2a21cecae3e92fc0"
      },
      "cell_type": "markdown",
      "source": "### Fixed Training Split\nThe reason why we need to do a fixed training test split that fetches the last few rows of the training dataset is to avoid odd results, since randomly choosing rows will cause the validation dataset to be filled with rows with different timestamps."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96cba104e412b54f84ec6f348c633df92577c90c"
      },
      "cell_type": "code",
      "source": "def fixed_train_test_split(X, y, train_size):\n    \n    # round train size\n    train_size = int(train_size * len(X))\n    \n    # split data\n    X_train, y_train = X[train_size:], y[train_size:]\n    X_valid, y_valid = X[:train_size], y[:train_size]\n    \n    return X_train, y_train, X_valid, y_valid",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f554061d572cb8f8fd06cef48c3ef633e9db17d0"
      },
      "cell_type": "code",
      "source": "X_train, y_train, X_valid, y_valid = fixed_train_test_split(X_train, y_train, 0.85)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "555aa54327cc8ffdacc43554af32d5105c775169"
      },
      "cell_type": "markdown",
      "source": "### Using LightGBM for modelling"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c29621021859ac6c5f48807373635cb0bfc166e8"
      },
      "cell_type": "code",
      "source": "import lightgbm as lgb\n\nparams = {\"objective\" : \"binary\",\n          \"metric\" : \"binary_logloss\",\n          \"num_leaves\" : 60,\n          \"max_depth\": -1,\n          \"learning_rate\" : 0.01,\n          \"bagging_fraction\" : 0.9,  # subsample\n          \"feature_fraction\" : 0.9,  # colsample_bytree\n          \"bagging_freq\" : 5,        # subsample_freq\n          \"bagging_seed\" : 2018,\n          \"verbosity\" : -1 }\n\nlgtrain, lgval = lgb.Dataset(X_train, y_train), lgb.Dataset(X_valid, y_valid)\nlgb_model = lgb.train(params, lgtrain, 2000, valid_sets=[lgtrain, lgval], early_stopping_rounds=100, verbose_eval=200)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "36a59163f089651745eaf40bb6250261a23aab24"
      },
      "cell_type": "markdown",
      "source": "<a id='section4'></a>\n## Step 4. Applying the Model\n"
    },
    {
      "metadata": {
        "_uuid": "f20c20364f574cded4dd1fb93f0183d88a58657e"
      },
      "cell_type": "markdown",
      "source": "Predictions will be made through a for loop, and apply all the functions above onto the test dataset."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7b135a2631912100c434e78d21269b6aed4c4e37"
      },
      "cell_type": "code",
      "source": "def get_X(market_test_df, news_test_df):\n    X_test = data_step1(market_test_df, news_test_df)\n    X_test = data_step2(X_test)\n    X_test = X_test[[f for f in X_train.columns if f not in ['time', 'assetCode', 'universe', 'assetName', 'returnsOpenNextMktres10',\n                                                          'headline', 'subjects', 'audiences']]].fillna(0)\n    return X_test\n\ndef make_predictions(market_obs_df, news_obs_df):\n    \n    # predict using given model\n    X_test = get_X(market_obs_df, news_obs_df)\n    prediction_values = np.clip(lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration), -1, 1)\n\n    return prediction_values\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73d421583382e278112c0a8e10e617a4582e072f"
      },
      "cell_type": "code",
      "source": "%%time\nfor (market_obs_df, news_obs_df, predictions_template_df) in env.get_prediction_days(): # Looping over days from start of 2017 to 2019-07-15\n    \n    # make predictions\n    predictions_template_df['confidenceValue'] = make_predictions(market_obs_df, news_obs_df)\n    \n    # save predictions\n    env.predict(predictions_template_df)\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3bd33d9ae37985f04a5afee2e84e4db712018f49"
      },
      "cell_type": "code",
      "source": "env.write_submission_file()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cbcb1733a22212e40026b5bafdbb982b667446d6"
      },
      "cell_type": "markdown",
      "source": "**Sources:**\n* [Market Data NN Baseline by Christofhenkel](https://www.kaggle.com/christofhenkel/market-data-nn-baseline)\n* [a simple model using the market and news data by Bguberfain](https://www.kaggle.com/bguberfain/a-simple-model-using-the-market-and-news-data)\n* [Amateur Hour - Using Headlines to Predict Stocks by Magichanics](https://www.kaggle.com/magichanics/amateur-hour-using-headlines-to-predict-stocks)\n* [Simple Quant Features by Youhanlee](https://www.kaggle.com/youhanlee/simple-quant-features-using-python)\n* [>0.64 in 100 lines by rabaman](https://www.kaggle.com/rabaman/0-64-in-100-lines/comments)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}