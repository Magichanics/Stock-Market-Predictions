{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "# Amateur Hour - Predicting Stocks using LightGBM (Market Data Only)\n### Starter Kernel by ``Magichanics`` \n*([GitHub](https://github.com/Magichanics) - [Kaggle](https://www.kaggle.com/magichanics))*\n\nThis is more of an improvement in organization and efficiency compared to my previous notebook. The reason why I've decided to create a Market Data Only kernel is because of how small the runtime is.\n\nFeel free to post suggestions or criticisms! "
    },
    {
      "metadata": {
        "_uuid": "c6e9c58ee0984fd7aace750a5f542ceee09e17f0"
      },
      "cell_type": "markdown",
      "source": "## Table of Contents\n\n* [Step 1. Cleaning Dataset](#section1)\n* [Step 2. Feature Engineering](#section2)\n* [Step 3. Modelling using LightGBM](#section3)\n* [Step 4. Applying the Model](#section4)"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport os\nimport gc\nfrom itertools import chain\n\nimport matplotlib.pyplot as plt",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "85a94467c9c2550570e4e3bae4eb32f2bf6b95cd"
      },
      "cell_type": "code",
      "source": "import warnings\nwarnings.filterwarnings(\"ignore\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d9242e2e05ad6ae6897c99a33e224cc588621028",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "# import environment for data\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "451e7c9bd35702323a7df4db34b91921254a1369"
      },
      "cell_type": "code",
      "source": "(market_train_df, news_train_df) = env.get_training_data()\nsampling = False\nif sampling:\n    market_train_df = market_train_df.tail(400_000)\ndel news_train_df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a58dabdb861587a6dc5d2917ecc742727f3d1e60"
      },
      "cell_type": "markdown",
      "source": "<a id='section1'></a>\n## Step 1. Cleaning Dataset\n\nWe'll be getting rid of a bit of data from the market dataset."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98ddae667a406f38302133fe776106f15e873eca",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "market_train_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "39a5a4da7d833cd2e0c2a9de9f6f30c6ec10f922"
      },
      "cell_type": "markdown",
      "source": "### Getting rid of Data prior to 2010\nData affected by the Financial Crisis (and January 2010 data) may not benefit this model."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c35fe1a86234868804664c40675a7a4468b48d70"
      },
      "cell_type": "code",
      "source": "from datetime import datetime, timedelta\nstart = datetime(2010, 2, 1, 0, 0, 0).date()\nmarket_train_df = market_train_df.loc[market_train_df['time'].dt.date >= start].reset_index(drop=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "13f7b88ce7c3473340251903b17106af89e8e213"
      },
      "cell_type": "markdown",
      "source": "### Cleaning Data\nWe will be only keeping the features with good correlation with the dataset."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b2a9a6a69a66557f69b30b5e27553a2ba15bc933"
      },
      "cell_type": "code",
      "source": "def clean_data(market_df, train=True):\n    \n    # get only what's necessary\n    valid_market_cols = ['time', 'assetCode', 'volume', 'close', 'open',\\\n                           'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\\\n                           'returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\n    if train:\n        valid_market_cols += ['returnsOpenNextMktres10']\n    market_df = market_df[valid_market_cols]\n\n    return market_df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5e814659d584d93fa399c07746d050ba5ca62b2e"
      },
      "cell_type": "code",
      "source": "X_train = clean_data(market_train_df, train=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b4b177c09e0546499a260041b7fb604673813ccf"
      },
      "cell_type": "code",
      "source": "X_train.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "91780d18359c8faf6cf6e224995aa882926754db"
      },
      "cell_type": "code",
      "source": "del market_train_df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b24a1eb7424ef10af9dbb4ee7c177dfefa220f51"
      },
      "cell_type": "markdown",
      "source": "<a id='section2'></a>\n## Step 2. Feature Engineering\n\nFrom Quant features to text processing features."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "434e633c799d075f6dcc14e6d00104b5cafbe0b4"
      },
      "cell_type": "code",
      "source": "X_train.tail()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bb3b997307f60939c4b4a36845dc264109f60c81"
      },
      "cell_type": "markdown",
      "source": "### Entire Market and Individual Asset Lag Features\nWe are going to be obtaining Quant Features from both the entire market dataframe and from each individual asset based on assetCode.\n\nSource: https://www.kaggle.com/qqgeogor/eda-script-67"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "40c71a4a4b0d16255a0d8df0eaed31353850608e"
      },
      "cell_type": "code",
      "source": "from multiprocessing import Pool\n\ndef create_lag(df_code,n_lag=[3,7,14,],shift_size=1):\n    code = df_code['assetCode'].unique()\n    \n    for col in return_features:\n        for window in n_lag:\n            rolled = df_code[col].shift(shift_size).rolling(window=window)\n            lag_mean = rolled.mean()\n            lag_max = rolled.max()\n            lag_min = rolled.min()\n            lag_std = rolled.std()\n            df_code['%s_lag_%s_mean'%(col,window)] = lag_mean\n            df_code['%s_lag_%s_max'%(col,window)] = lag_max\n            df_code['%s_lag_%s_min'%(col,window)] = lag_min\n\n    return df_code.fillna(-1)\n\ndef generate_lag_features(df,n_lag = [3,7,14]):\n    \n    assetCodes = df['assetCode'].unique()\n    all_df = []\n    df_codes = df.groupby('assetCode')\n    df_codes = [df_code[1][['time','assetCode']+return_features] for df_code in df_codes]\n    \n    pool = Pool(4)\n    all_df = pool.map(create_lag, df_codes)\n    \n    new_df = pd.concat(all_df)  \n    new_df.drop(return_features+['time', 'assetCode'],axis=1,inplace=True)\n    new_df = pd.concat([df, new_df], axis=1, sort=False)\n    pool.close()\n    \n    return new_df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3e74748b76d9486be16965296832163b8030d1aa"
      },
      "cell_type": "code",
      "source": "%%time\nreturn_features = ['returnsClosePrevMktres10','returnsClosePrevRaw10','open','close', 'volume']\nX_train = generate_lag_features(X_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "41ffe3d7dba3f05b87677d58eb65af8025ab6987"
      },
      "cell_type": "code",
      "source": "X_train.dropna().head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ee95784fb1993f7f76453efc7714a23fb6e83f9a"
      },
      "cell_type": "markdown",
      "source": "### Clustering\nWe will be clustering the open and close features using KMeans."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "85c1e43b0e3d2b082a3e2badb0c13da2f3b0562c"
      },
      "cell_type": "code",
      "source": "from sklearn.cluster import KMeans\n\n# suggesting -> add multiprocessing to KMeans\n\ndef clustering(X):\n\n    def cluster_modelling(features):\n        df_set = X[features].fillna(0)\n        cluster_model = KMeans(n_clusters = 4)\n        cluster_model.fit(df_set)\n        return cluster_model.predict(df_set)\n    \n    X['cluster_open_close'] = cluster_modelling(['open', 'close'])\n    X['cluster_prev10'] = cluster_modelling(['returnsClosePrevMktres10', 'returnsClosePrevRaw10'])\n    \n    return X",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4da114e64381b829639cfceac5c69c0d96f2999e"
      },
      "cell_type": "code",
      "source": "%%time\nX_train = clustering(X_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bc5e1e76b0da8d54944b2f052a260c6262b0c14b"
      },
      "cell_type": "markdown",
      "source": "### Misc. Features\nInclues the following features:\n* Daily Difference"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "efb62b12fc7e92dc4ca1047faa85e796b33f2847"
      },
      "cell_type": "code",
      "source": "def misc_features(X):\n    \n    # Adding daily difference\n    new_col = X[\"close\"] - X[\"open\"]\n    X.insert(loc=6, column=\"daily_diff\", value=new_col)\n    X['close_to_open'] =  np.abs(X['close'] / X['open'])\n    \n    # extra features\n    X['bartrend'] = X['close'] / X['open']\n    X['average'] = (X['close'] + X['open'])/2\n    X['pricevolume'] = X['volume'] * X['close']\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "522167cbd0bff9410e5fdab6b4b7ccabbef85b73"
      },
      "cell_type": "code",
      "source": "misc_features(X_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a43e6531abec41d694afed23ddb3c34ea113bda5"
      },
      "cell_type": "code",
      "source": "X_train.dropna().tail()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ab3199b41454b6093f0cd2be4dddf3b869824596"
      },
      "cell_type": "markdown",
      "source": "<a id='section3'></a>\n## Step 3. Modelling using LightGBM"
    },
    {
      "metadata": {
        "_uuid": "5853a3b60388bbab1fcd48a0d98d446d0f3d5826"
      },
      "cell_type": "markdown",
      "source": "### Preparing Datasets for Modelling"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "64fd6fa8dddce53665260f06c7c828625105fe95"
      },
      "cell_type": "code",
      "source": "y_train = X_train['returnsOpenNextMktres10']\nX_train = X_train[[f for f in X_train.columns if f not in ['time', 'assetCode', 'universe', 'assetName', 'returnsOpenNextMktres10',\n                                                          'headline', 'subjects', 'audiences']]].fillna(0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "76abdc01a2846fe429c2364a2a21cecae3e92fc0"
      },
      "cell_type": "markdown",
      "source": "### Fixed Training Split\nThe reason why we need to do a fixed training test split that fetches the last few rows of the training dataset is to avoid odd results, since randomly choosing rows will cause the validation dataset to be filled with rows with different timestamps."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96cba104e412b54f84ec6f348c633df92577c90c"
      },
      "cell_type": "code",
      "source": "def fixed_train_test_split(X, y, train_size):\n    \n    # round train size\n    train_size = int(train_size * len(X))\n    \n    # split data\n    X_train, y_train = X[train_size:], y[train_size:]\n    X_valid, y_valid = X[:train_size], y[:train_size]\n    \n    return X_train, y_train, X_valid, y_valid",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f554061d572cb8f8fd06cef48c3ef633e9db17d0"
      },
      "cell_type": "code",
      "source": "X_train, y_train, X_valid, y_valid = fixed_train_test_split(X_train, y_train, 0.85)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "555aa54327cc8ffdacc43554af32d5105c775169"
      },
      "cell_type": "markdown",
      "source": "### Using LightGBM for modelling\n\nModel from:\nhttps://www.kaggle.com/rabaman/0-64-in-100-lines/code"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c29621021859ac6c5f48807373635cb0bfc166e8"
      },
      "cell_type": "code",
      "source": "import lightgbm as lgb\n\nparams = {\"objective\" : \"binary\",\n          \"metric\" : \"binary_logloss\",\n          \"num_leaves\" : 60,\n          \"max_depth\": -1,\n          \"learning_rate\" : 0.01,\n          \"bagging_fraction\" : 0.9,  # subsample\n          \"feature_fraction\" : 0.9,  # colsample_bytree\n          \"bagging_freq\" : 5,        # subsample_freq\n          \"bagging_seed\" : 2018,\n          \"verbosity\" : -1 }\n\nlgtrain, lgval = lgb.Dataset(X_train, y_train), lgb.Dataset(X_valid, y_valid)\nlgb_model = lgb.train(params, lgtrain, 2000, valid_sets=[lgtrain, lgval], early_stopping_rounds=100, verbose_eval=200)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "36a59163f089651745eaf40bb6250261a23aab24"
      },
      "cell_type": "markdown",
      "source": "<a id='section4'></a>\n## Step 4. Applying the Model\n"
    },
    {
      "metadata": {
        "_uuid": "f20c20364f574cded4dd1fb93f0183d88a58657e"
      },
      "cell_type": "markdown",
      "source": "Predictions will be made through a for loop, and apply all the functions above onto the test dataset."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7b135a2631912100c434e78d21269b6aed4c4e37"
      },
      "cell_type": "code",
      "source": "def get_X(market_test_df):\n    \n    X_test = clean_data(market_test_df, train=False)\n    X_test = generate_lag_features(X_test)\n    X_test = clustering(X_test)\n    misc_features(X_test)\n    X_test = X_test[[f for f in X_test.columns if f not in ['time', 'assetCode', 'universe', \\\n                                                            'assetName', 'returnsOpenNextMktres10',\\\n                                                          'headline', 'subjects', 'audiences']]].fillna(0)\n    \n    return X_test\n\ndef make_predictions(market_obs_df):\n    \n    # predict using given model\n    X_test = get_X(market_obs_df)\n    prediction_values = lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration)  * 2 - 1\n\n    return prediction_values\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73d421583382e278112c0a8e10e617a4582e072f"
      },
      "cell_type": "code",
      "source": "%%time\nn_days = 0\nfor (market_obs_df, news_obs_df, predictions_template_df) in env.get_prediction_days(): # Looping over days from start of 2017 to 2019-07-15\n    \n    n_days +=1\n    if n_days % 50 == 0:\n        print(n_days)\n    \n    # make predictions\n    predictions_template_df['confidenceValue'] = make_predictions(market_obs_df)\n    \n    # save predictions\n    env.predict(predictions_template_df)\n    \nenv.write_submission_file()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cbcb1733a22212e40026b5bafdbb982b667446d6"
      },
      "cell_type": "markdown",
      "source": "**Sources:**\n* [Amateur Hour - Using Headlines to Predict Stocks by Magichanics](https://www.kaggle.com/magichanics/amateur-hour-using-headlines-to-predict-stocks)\n* [Simple Quant Features by Youhanlee](https://www.kaggle.com/youhanlee/simple-quant-features-using-python)\n* [>0.64 in 100 lines by rabaman](https://www.kaggle.com/rabaman/0-64-in-100-lines/comments)\n* [eda script 67 by qqgeogor](https://www.kaggle.com/qqgeogor/eda-script-67)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}