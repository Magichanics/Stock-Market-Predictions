{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "# \"Stock\" Grade Neural Network\n### Starter Kernel by ``Magichanics`` \n*([GitHub](https://github.com/Magichanics) - [Kaggle](https://www.kaggle.com/magichanics))*\n\nWith more features from public kernels, as well as the idea of using Neural Networks for modelling, I've decided to do some experimenting myself in hopes of producing the best results. Feel free to post suggestions or criticisms!"
    },
    {
      "metadata": {
        "_uuid": "c6e9c58ee0984fd7aace750a5f542ceee09e17f0"
      },
      "cell_type": "markdown",
      "source": "## Table of Contents\n\n* [Step 1. Merging Datasets](#section1)\n* [Step 2. Feature Engineering](#section2)\n* [Step 3. Modelling using Keras' Neural Network](#section3)\n* [Step 4. Applying the Model](#section4)"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport os\nimport gc\nfrom itertools import chain\n\nimport matplotlib.pyplot as plt",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d9242e2e05ad6ae6897c99a33e224cc588621028",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# import environment for data\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Loading the data... This could take a minute.\nDone!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "451e7c9bd35702323a7df4db34b91921254a1369"
      },
      "cell_type": "code",
      "source": "(market_train_df, news_train_df) = env.get_training_data()\nmarket_train_df = market_train_df.tail(400_000)\nnews_train_df = news_train_df.tail(1_000_000)",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a58dabdb861587a6dc5d2917ecc742727f3d1e60"
      },
      "cell_type": "markdown",
      "source": "<a id='section1'></a>\n## Step 1. Merging Datasets\n\nWhile most of the notebooks focuses only on the market dataset, I'm going to attempt on bringing both the news and market dataset together."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98ddae667a406f38302133fe776106f15e873eca",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "market_train_df.head()",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "                             time   ...    universe\n3672956 2016-02-19 22:00:00+00:00   ...         1.0\n3672957 2016-02-19 22:00:00+00:00   ...         0.0\n3672958 2016-02-19 22:00:00+00:00   ...         1.0\n3672959 2016-02-19 22:00:00+00:00   ...         1.0\n3672960 2016-02-19 22:00:00+00:00   ...         1.0\n\n[5 rows x 16 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>assetCode</th>\n      <th>assetName</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw1</th>\n      <th>returnsOpenPrevRaw1</th>\n      <th>returnsClosePrevMktres1</th>\n      <th>returnsOpenPrevMktres1</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n      <th>universe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3672956</th>\n      <td>2016-02-19 22:00:00+00:00</td>\n      <td>SPWR.O</td>\n      <td>SunPower Corp</td>\n      <td>4109129.0</td>\n      <td>21.14</td>\n      <td>22.25</td>\n      <td>-0.074431</td>\n      <td>-0.094055</td>\n      <td>-0.074354</td>\n      <td>-0.081761</td>\n      <td>-0.175828</td>\n      <td>-0.102823</td>\n      <td>-0.180055</td>\n      <td>-0.111746</td>\n      <td>0.068726</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3672957</th>\n      <td>2016-02-19 22:00:00+00:00</td>\n      <td>SQM.N</td>\n      <td>Sociedad Quimica y Minera de Chile SA</td>\n      <td>414021.0</td>\n      <td>17.15</td>\n      <td>16.94</td>\n      <td>0.002924</td>\n      <td>-0.033105</td>\n      <td>0.002975</td>\n      <td>-0.025269</td>\n      <td>0.051502</td>\n      <td>0.057428</td>\n      <td>0.049969</td>\n      <td>0.054736</td>\n      <td>-0.003696</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3672958</th>\n      <td>2016-02-19 22:00:00+00:00</td>\n      <td>SRC.N</td>\n      <td>Spirit Realty Capital Inc</td>\n      <td>7481287.0</td>\n      <td>11.09</td>\n      <td>11.09</td>\n      <td>-0.001800</td>\n      <td>0.024954</td>\n      <td>-0.001777</td>\n      <td>0.029012</td>\n      <td>0.038390</td>\n      <td>0.052182</td>\n      <td>0.035912</td>\n      <td>0.046627</td>\n      <td>-0.067333</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3672959</th>\n      <td>2016-02-19 22:00:00+00:00</td>\n      <td>SRCL.O</td>\n      <td>Stericycle Inc</td>\n      <td>898932.0</td>\n      <td>109.66</td>\n      <td>111.30</td>\n      <td>-0.016855</td>\n      <td>0.004241</td>\n      <td>-0.016824</td>\n      <td>0.008331</td>\n      <td>-0.054166</td>\n      <td>-0.052121</td>\n      <td>-0.055767</td>\n      <td>-0.054056</td>\n      <td>-0.044206</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3672960</th>\n      <td>2016-02-19 22:00:00+00:00</td>\n      <td>SRE.N</td>\n      <td>Sempra Energy</td>\n      <td>2143306.0</td>\n      <td>97.25</td>\n      <td>96.66</td>\n      <td>0.003819</td>\n      <td>0.014058</td>\n      <td>0.003833</td>\n      <td>0.015573</td>\n      <td>0.020355</td>\n      <td>0.012359</td>\n      <td>0.019882</td>\n      <td>0.011141</td>\n      <td>-0.006034</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3573a5f315d0fad58e8102d3a80d1f8cb269f8b7"
      },
      "cell_type": "code",
      "source": "news_train_df.head()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "                             time      ...       volumeCounts7D\n8328750 2015-12-08 13:56:53+00:00      ...                   63\n8328751 2015-12-08 13:57:20+00:00      ...                  167\n8328752 2015-12-08 13:57:20+00:00      ...                  166\n8328753 2015-12-08 13:57:37+00:00      ...                   10\n8328754 2015-12-08 13:57:41+00:00      ...                   17\n\n[5 rows x 35 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>sourceTimestamp</th>\n      <th>firstCreated</th>\n      <th>sourceId</th>\n      <th>headline</th>\n      <th>urgency</th>\n      <th>takeSequence</th>\n      <th>provider</th>\n      <th>subjects</th>\n      <th>audiences</th>\n      <th>bodySize</th>\n      <th>companyCount</th>\n      <th>headlineTag</th>\n      <th>marketCommentary</th>\n      <th>sentenceCount</th>\n      <th>wordCount</th>\n      <th>assetCodes</th>\n      <th>assetName</th>\n      <th>firstMentionSentence</th>\n      <th>relevance</th>\n      <th>sentimentClass</th>\n      <th>sentimentNegative</th>\n      <th>sentimentNeutral</th>\n      <th>sentimentPositive</th>\n      <th>sentimentWordCount</th>\n      <th>noveltyCount12H</th>\n      <th>noveltyCount24H</th>\n      <th>noveltyCount3D</th>\n      <th>noveltyCount5D</th>\n      <th>noveltyCount7D</th>\n      <th>volumeCounts12H</th>\n      <th>volumeCounts24H</th>\n      <th>volumeCounts3D</th>\n      <th>volumeCounts5D</th>\n      <th>volumeCounts7D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8328750</th>\n      <td>2015-12-08 13:56:53+00:00</td>\n      <td>2015-12-08 13:56:53+00:00</td>\n      <td>2015-12-08 13:56:53+00:00</td>\n      <td>f9c4067a6d20f21b</td>\n      <td>CHESAPEAKE ENERGY CORP SHARES EXTEND LOSSES, N...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'BLR', 'STX', 'OILG', 'EXPL', 'HOT', 'ENER', ...</td>\n      <td>{'E', 'U'}</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>2</td>\n      <td>21</td>\n      <td>{'CHK.N'}</td>\n      <td>Chesapeake Energy Corp</td>\n      <td>1</td>\n      <td>1.00000</td>\n      <td>-1</td>\n      <td>0.819143</td>\n      <td>0.125228</td>\n      <td>0.055629</td>\n      <td>21</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>7</td>\n      <td>9</td>\n      <td>17</td>\n      <td>23</td>\n      <td>24</td>\n      <td>41</td>\n      <td>63</td>\n    </tr>\n    <tr>\n      <th>8328751</th>\n      <td>2015-12-08 13:57:20+00:00</td>\n      <td>2015-12-08 13:57:20+00:00</td>\n      <td>2015-12-08 13:57:20+00:00</td>\n      <td>749e57557c589fca</td>\n      <td>REG - Societe Generale SA Anheuser-Busch InBev...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>LSE</td>\n      <td>{'NEWR', 'FOBE', 'WEU', 'BEVS', 'NCYC', 'LEN',...</td>\n      <td>{'LSEN'}</td>\n      <td>21427</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>47</td>\n      <td>1528</td>\n      <td>{'ABI.BR', 'BUD.N'}</td>\n      <td>Anheuser Busch Inbev SA</td>\n      <td>1</td>\n      <td>1.00000</td>\n      <td>0</td>\n      <td>0.014524</td>\n      <td>0.801992</td>\n      <td>0.183484</td>\n      <td>62</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>22</td>\n      <td>30</td>\n      <td>51</td>\n      <td>90</td>\n      <td>167</td>\n    </tr>\n    <tr>\n      <th>8328752</th>\n      <td>2015-12-08 13:57:20+00:00</td>\n      <td>2015-12-08 13:57:19+00:00</td>\n      <td>2015-12-08 13:57:19+00:00</td>\n      <td>e61c180b2be5eb45</td>\n      <td>REG - Societe Generale SA Anheuser-Busch InBev...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>LSE</td>\n      <td>{'NEWR', 'FOBE', 'WEU', 'BEVS', 'NCYC', 'LEN',...</td>\n      <td>{'LSEN'}</td>\n      <td>59958</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>53</td>\n      <td>4563</td>\n      <td>{'ABI.BR', 'BUD.N'}</td>\n      <td>Anheuser Busch Inbev SA</td>\n      <td>1</td>\n      <td>1.00000</td>\n      <td>1</td>\n      <td>0.035002</td>\n      <td>0.161918</td>\n      <td>0.803080</td>\n      <td>176</td>\n      <td>19</td>\n      <td>25</td>\n      <td>46</td>\n      <td>74</td>\n      <td>133</td>\n      <td>21</td>\n      <td>29</td>\n      <td>50</td>\n      <td>89</td>\n      <td>166</td>\n    </tr>\n    <tr>\n      <th>8328753</th>\n      <td>2015-12-08 13:57:37+00:00</td>\n      <td>2015-12-08 13:57:37+00:00</td>\n      <td>2015-12-08 13:57:37+00:00</td>\n      <td>35e01becdbd06d17</td>\n      <td>IIROC Trade Resumption - BIP.PR.B &lt;BIP.N&gt;</td>\n      <td>3</td>\n      <td>1</td>\n      <td>CNW</td>\n      <td>{'NEWR', 'LEN', 'ELEU', 'FINS', 'US', 'DFIN', ...</td>\n      <td>{'CNR', 'CNW'}</td>\n      <td>753</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>8</td>\n      <td>137</td>\n      <td>{'BIP.N'}</td>\n      <td>Brookfield Infrastructure Partners LP</td>\n      <td>4</td>\n      <td>0.57735</td>\n      <td>-1</td>\n      <td>0.811987</td>\n      <td>0.129426</td>\n      <td>0.058586</td>\n      <td>87</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>8328754</th>\n      <td>2015-12-08 13:57:41+00:00</td>\n      <td>2015-12-08 13:57:41+00:00</td>\n      <td>2015-12-08 13:57:41+00:00</td>\n      <td>36a59986b3a81936</td>\n      <td>TRANSOCEAN'S U.S.-LISTED SHARES DOWN 2.41 PCT ...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'BLR', 'STX', 'WEU', 'HOT', 'CH', 'DRIL', 'EN...</td>\n      <td>{'E', 'U'}</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>1</td>\n      <td>14</td>\n      <td>{'RIG.N', 'RIGN.VX', 'RIGN.BN'}</td>\n      <td>Transocean Ltd</td>\n      <td>1</td>\n      <td>1.00000</td>\n      <td>-1</td>\n      <td>0.819123</td>\n      <td>0.125241</td>\n      <td>0.055637</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>14</td>\n      <td>17</td>\n      <td>17</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "13f7b88ce7c3473340251903b17106af89e8e213"
      },
      "cell_type": "markdown",
      "source": "### Cleaning Data\nWe will be removing the rows with the following qualities:\n* Empty headlines\n* Repeat headlines\n* Urgency of 2\n* Null assetName"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b2a9a6a69a66557f69b30b5e27553a2ba15bc933"
      },
      "cell_type": "code",
      "source": "def clean_data(market_df, news_df, train=True):\n    \n    # get rid of invalid rows\n    news_df = news_df[news_df.headline != '']\n    news_df = news_df[news_df.urgency != 2]\n    \n    # remove duplicate headlines with the same assetCodes\n    news_df = news_df.drop_duplicates(subset=['assetCodes', 'headline'],keep='first')\n    \n#     if train:\n#         market_df.drop('assetName', axis=1, inplace=True)\n\n    return market_df, news_df",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5e814659d584d93fa399c07746d050ba5ca62b2e"
      },
      "cell_type": "code",
      "source": "market_train_df, news_train_df = clean_data(market_train_df, news_train_df, train=True)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "54ea9c0ee8287b5edc984a84c07030a0e106d6c8"
      },
      "cell_type": "code",
      "source": "news_train_df.shape",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "(869377, 35)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b4b177c09e0546499a260041b7fb604673813ccf"
      },
      "cell_type": "code",
      "source": "market_train_df.shape",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "(400000, 16)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "486d593869589819aefadb4345af1b5db0060ffc"
      },
      "cell_type": "markdown",
      "source": "### Expanding News data\nWe are going to be splitting the news data by assetCode."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "29b5aa276e3bfb61ae5a83dbb24162da1f0a72c6"
      },
      "cell_type": "code",
      "source": "def expanding_news(news_df):\n    \n    # split to list\n    news_output = news_df.copy()\n    news_output['assetCodes'] = news_output['assetCodes'].str.findall(f\"'([\\w\\./]+)'\")\n    \n    # separate to assetcodes\n    assetCodes_expanded = list(chain(*news_output['assetCodes']))\n    assetCodes_index = news_df.index.repeat(news_output['assetCodes'].apply(len))\n    assert len(assetCodes_index) == len(assetCodes_expanded)\n    df_assetCodes = pd.DataFrame({'level_0': assetCodes_index, 'assetCode': assetCodes_expanded})\n    \n    # merge to dataframe\n    merging_cols = [f for f in news_output if f not in ['assetCodes', 'sourceId']]\n    news_df_expanded = pd.merge(df_assetCodes, news_output[merging_cols], left_on='level_0', \n                                right_index=True, suffixes=(['','_old']))\n    \n    return news_df_expanded",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "783cae5ad82f345e1d620fcdf7b22e9c76fa3e29"
      },
      "cell_type": "code",
      "source": "expand_train_df = expanding_news(news_train_df)",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "368a6fd592fc50eeefa583123cb1b1fa7ad28dd3"
      },
      "cell_type": "code",
      "source": "expand_train_df.tail()",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "         level_0 assetCode      ...       volumeCounts5D volumeCounts7D\n1608941  9328747    SGEN.O      ...                   41             41\n1608942  9328747   SGEN.OQ      ...                   41             41\n1608943  9328748    IPDN.O      ...                    3              3\n1608944  9328748   IPDN.OQ      ...                    3              3\n1608945  9328749     JFC.N      ...                    0              0\n\n[5 rows x 35 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>assetCode</th>\n      <th>time</th>\n      <th>sourceTimestamp</th>\n      <th>firstCreated</th>\n      <th>headline</th>\n      <th>urgency</th>\n      <th>takeSequence</th>\n      <th>provider</th>\n      <th>subjects</th>\n      <th>audiences</th>\n      <th>bodySize</th>\n      <th>companyCount</th>\n      <th>headlineTag</th>\n      <th>marketCommentary</th>\n      <th>sentenceCount</th>\n      <th>wordCount</th>\n      <th>assetName</th>\n      <th>firstMentionSentence</th>\n      <th>relevance</th>\n      <th>sentimentClass</th>\n      <th>sentimentNegative</th>\n      <th>sentimentNeutral</th>\n      <th>sentimentPositive</th>\n      <th>sentimentWordCount</th>\n      <th>noveltyCount12H</th>\n      <th>noveltyCount24H</th>\n      <th>noveltyCount3D</th>\n      <th>noveltyCount5D</th>\n      <th>noveltyCount7D</th>\n      <th>volumeCounts12H</th>\n      <th>volumeCounts24H</th>\n      <th>volumeCounts3D</th>\n      <th>volumeCounts5D</th>\n      <th>volumeCounts7D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1608941</th>\n      <td>9328747</td>\n      <td>SGEN.O</td>\n      <td>2016-12-30 21:57:00+00:00</td>\n      <td>2016-12-30 21:57:00+00:00</td>\n      <td>2016-12-30 21:57:00+00:00</td>\n      <td>EQUITY ALERT: Rosen Law Firm Announces Investi...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>BSW</td>\n      <td>{'CMSS', 'CLJ', 'GEN', 'NEWR', 'HECA', 'PHMR',...</td>\n      <td>{'BSW', 'CNR'}</td>\n      <td>3734</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>16</td>\n      <td>664</td>\n      <td>Seattle Genetics Inc</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>-1</td>\n      <td>0.651900</td>\n      <td>0.227707</td>\n      <td>0.120393</td>\n      <td>360</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>18</td>\n      <td>41</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>1608942</th>\n      <td>9328747</td>\n      <td>SGEN.OQ</td>\n      <td>2016-12-30 21:57:00+00:00</td>\n      <td>2016-12-30 21:57:00+00:00</td>\n      <td>2016-12-30 21:57:00+00:00</td>\n      <td>EQUITY ALERT: Rosen Law Firm Announces Investi...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>BSW</td>\n      <td>{'CMSS', 'CLJ', 'GEN', 'NEWR', 'HECA', 'PHMR',...</td>\n      <td>{'BSW', 'CNR'}</td>\n      <td>3734</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>16</td>\n      <td>664</td>\n      <td>Seattle Genetics Inc</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>-1</td>\n      <td>0.651900</td>\n      <td>0.227707</td>\n      <td>0.120393</td>\n      <td>360</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>18</td>\n      <td>41</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>1608943</th>\n      <td>9328748</td>\n      <td>IPDN.O</td>\n      <td>2016-12-30 21:58:53+00:00</td>\n      <td>2016-12-30 21:58:53+00:00</td>\n      <td>2016-12-30 21:58:53+00:00</td>\n      <td>PROFESSIONAL DIVERSITY NETWORK INC - FILES FOR...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'BLR', 'SWIT', 'ITSE', 'SISU', 'BACT', 'TMT',...</td>\n      <td>{'E', 'U'}</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>1</td>\n      <td>23</td>\n      <td>Professional Diversity Network Inc</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>-1</td>\n      <td>0.816252</td>\n      <td>0.126928</td>\n      <td>0.056819</td>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1608944</th>\n      <td>9328748</td>\n      <td>IPDN.OQ</td>\n      <td>2016-12-30 21:58:53+00:00</td>\n      <td>2016-12-30 21:58:53+00:00</td>\n      <td>2016-12-30 21:58:53+00:00</td>\n      <td>PROFESSIONAL DIVERSITY NETWORK INC - FILES FOR...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'BLR', 'SWIT', 'ITSE', 'SISU', 'BACT', 'TMT',...</td>\n      <td>{'E', 'U'}</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>1</td>\n      <td>23</td>\n      <td>Professional Diversity Network Inc</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>-1</td>\n      <td>0.816252</td>\n      <td>0.126928</td>\n      <td>0.056819</td>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1608945</th>\n      <td>9328749</td>\n      <td>JFC.N</td>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>JPMorgan China Region Fund, Inc. Board to Subm...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>BSW</td>\n      <td>{'CMSS', 'NEWR', 'INVT', 'BACT', 'BSUP', 'INDS...</td>\n      <td>{'BSW', 'CNR'}</td>\n      <td>2969</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>15</td>\n      <td>492</td>\n      <td>JPMorgan China Region Fund Inc</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.130152</td>\n      <td>0.388845</td>\n      <td>0.481002</td>\n      <td>383</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3e4b182a9fd045db6a0ef4941324471ef60496f6"
      },
      "cell_type": "code",
      "source": "market_train_df.tail()",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "                             time   ...    universe\n4072951 2016-12-30 22:00:00+00:00   ...         0.0\n4072952 2016-12-30 22:00:00+00:00   ...         0.0\n4072953 2016-12-30 22:00:00+00:00   ...         0.0\n4072954 2016-12-30 22:00:00+00:00   ...         1.0\n4072955 2016-12-30 22:00:00+00:00   ...         1.0\n\n[5 rows x 16 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>assetCode</th>\n      <th>assetName</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw1</th>\n      <th>returnsOpenPrevRaw1</th>\n      <th>returnsClosePrevMktres1</th>\n      <th>returnsOpenPrevMktres1</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n      <th>universe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4072951</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZIOP.O</td>\n      <td>ZIOPHARM Oncology Inc</td>\n      <td>1608829.0</td>\n      <td>5.35</td>\n      <td>5.37</td>\n      <td>-0.003724</td>\n      <td>0.000000</td>\n      <td>0.000536</td>\n      <td>-0.001868</td>\n      <td>-0.165367</td>\n      <td>-0.138042</td>\n      <td>-0.139597</td>\n      <td>-0.135913</td>\n      <td>0.051189</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4072952</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZLTQ.O</td>\n      <td>ZELTIQ Aesthetics Inc</td>\n      <td>347830.0</td>\n      <td>43.52</td>\n      <td>43.62</td>\n      <td>-0.000689</td>\n      <td>0.000000</td>\n      <td>-0.000515</td>\n      <td>0.000493</td>\n      <td>0.002996</td>\n      <td>0.002989</td>\n      <td>0.008213</td>\n      <td>0.003210</td>\n      <td>-0.048555</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4072953</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZNGA.O</td>\n      <td>Zynga Inc</td>\n      <td>7396601.0</td>\n      <td>2.57</td>\n      <td>2.58</td>\n      <td>-0.011538</td>\n      <td>0.000000</td>\n      <td>-0.006004</td>\n      <td>-0.001034</td>\n      <td>-0.091873</td>\n      <td>-0.078571</td>\n      <td>-0.077252</td>\n      <td>-0.077188</td>\n      <td>0.011703</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4072954</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZTO.N</td>\n      <td>Unknown</td>\n      <td>3146519.0</td>\n      <td>12.07</td>\n      <td>12.50</td>\n      <td>-0.029743</td>\n      <td>0.007252</td>\n      <td>-0.028460</td>\n      <td>0.006719</td>\n      <td>-0.065066</td>\n      <td>-0.042146</td>\n      <td>-0.078104</td>\n      <td>-0.043813</td>\n      <td>0.083367</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4072955</th>\n      <td>2016-12-30 22:00:00+00:00</td>\n      <td>ZTS.N</td>\n      <td>Zoetis Inc</td>\n      <td>1701204.0</td>\n      <td>53.53</td>\n      <td>53.64</td>\n      <td>-0.001678</td>\n      <td>0.003091</td>\n      <td>0.005060</td>\n      <td>0.002885</td>\n      <td>0.023127</td>\n      <td>0.028177</td>\n      <td>0.026566</td>\n      <td>0.028719</td>\n      <td>-0.016220</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "e2c2e63e365f4b89f660f17ffbeb38545a0c05db"
      },
      "cell_type": "markdown",
      "source": "### Merge by time &  assetCode to News Article\nWe will be merging rows with the same time and assetCode."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e8e89a5e3cfd230ee137cf88be5f557765243d5e"
      },
      "cell_type": "code",
      "source": "from nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport re\n\nps = PorterStemmer()\nsw = stopwords.words('english')\n\n# this takes up a lot of time, so apply it when getting coefficients to filter out words.\ndef clean_headlines(headline):\n    \n    # remove numerical and convert to lowercase\n    headline =  re.sub('[^a-zA-Z]',' ',headline)\n    headline = headline.lower()\n    \n    # use stemming to simplify words\n    headline_words_rough = headline.split(' ')\n    \n    # check if stopwords are present in headlines\n    headline_words = []\n    for word in headline_words_rough:\n        if word not in sw:\n            # use stemming to simplify\n            headline_words.append(ps.stem(word))\n    \n    # join sentence back again\n    return ' '.join(headline_words)",
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "27a4e721de05191399c01e8724a39022d0f1b77e"
      },
      "cell_type": "code",
      "source": "def categorical_groupby(expand_df):\n    \n    # get categorical groupbys\n    main_cols = ['time', 'assetCode']\n    expand_headline_groupby = expand_train_df[main_cols + ['headline']].groupby(['time', 'assetCode'])\n    expand_cat_groupby = expand_train_df[main_cols + ['subjects', 'audiences']].groupby(['time', 'assetCode'])\n    \n    # split subjects and audiences\n    def cat_to_list(x):\n        result = []\n        for item in x:\n            result += item\n        return result\n    \n    # convert groupby to dataframes\n    expand_cat_df = expand_cat_groupby.transform(cat_to_list)\n    expand_headline_df = expand_headline_groupby.transform(lambda x: set(x)) # can't iterate through?\n    \n    # merge to categorical dataframes\n    return pd.concat([expand_cat_df, expand_headline_df], axis=1)\n    ",
      "execution_count": 135,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "02bbfecae766db4df6b63c24b49c2c294f9fab96"
      },
      "cell_type": "code",
      "source": "# WIP\ndef numerical_groupby(expand_df):\n    \n    news_agg_cols = [f for f in news_train_df.columns if 'novelty' in f or\n                    'volume' in f or\n                    'sentiment' in f or\n                    'bodySize' in f or\n                    'Count' in f or\n                    'marketCommentary' in f or\n                    'relevance' in f]\n    news_agg_dict = {}\n    for col in news_agg_cols:\n        news_agg_dict[col] = ['mean', 'sum', 'max', 'min']\n    news_agg_dict['urgency'] = ['min', 'count']\n    news_agg_dict['takeSequence'] = ['max']\n    \n    expand_agg_groupby = expand_train_df[['time', 'assetCode'] + news_agg_cols].groupby(['time', 'assetCode'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1653c7e20b8d9bcd4541c2f7da29549d3b1f7f2b"
      },
      "cell_type": "code",
      "source": "def get_matches(market_df, expand_df):\n    \n    # get temporary columns as data\n    temp_market_df = market_df[['time', 'assetCode']].copy()\n    temp_expand_df = expand_df[['time', 'assetCode']].copy()\n    \n    # get indecies\n    temp_expand_df['expand_index'] = temp_expand_df.index\n    \n    # join the two\n    temp_expand_df.set_index(['time', 'assetCode'], inplace=True)\n    temp_expand_market_df = temp_market_df.join(temp_expand_df, on=['time', 'assetCode'])\n    \n    # remove nulls\n    temp_expand_market_df = temp_expand_market_df[temp_expand_market_df.expand_index.isnull() == False]\n    expand_indicies = temp_expand_market_df['expand_index'].tolist()\n    \n    # do final cleanup\n    del temp_market_df\n    del temp_expand_df\n    \n    # fetch matches\n    return expand_df.loc[expand_indicies]\n\ndef merge_by_code(market_df, expand_df):\n    \n    # get expansion of rows\n    expand_df = get_matches(market_df, expand_df)\n    \n    # prepare categorical features for merging\n    expand_train_df['subjects'] = expand_train_df['subjects'].str.findall(f\"'([\\w\\./]+)'\")\n    expand_train_df['audiences'] = expand_train_df['audiences'].str.findall(f\"'([\\w\\./]+)'\")\n    expand_train_df['headline'] = expand_train_df['headline'].apply(clean_headlines)\n    \n    # groupby datasets\n    expand_cat_df = categorical_groupby(expand_df)\n    \n    # preform aggregations\n    ",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b24a1eb7424ef10af9dbb4ee7c177dfefa220f51"
      },
      "cell_type": "markdown",
      "source": "<a id='section2'></a>\n## Step 2. Feature Engineering\n\nFrom Quant features to text processing features."
    },
    {
      "metadata": {
        "_uuid": "f505dbf3b51058742233233511a2a6173c6d558f"
      },
      "cell_type": "markdown",
      "source": "### News Features\n* Last News Article - This feature will have the number of days it has been since a news article has targeted the given assetCode\n* Number of Articles Today/Week/Month - Fetches the number of Articles that was written on the assetCode during the given timeframe."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7e15e09b098a0272bf34512be2198fab2bce25ca"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7d1321bf02dbbcb9564eba994d75d0b4821f23bf"
      },
      "cell_type": "markdown",
      "source": "### Entire Market and Individual Asset Quant Features\nWe are going to be obtaining Quant Features from both the entire market dataframe and from each individual asset based on assetCode."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5364a8a9a634f55570c0ee68ade6830d3ba84350"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "26fb740a713963d533d1cb9684b81a3f6795525a"
      },
      "cell_type": "markdown",
      "source": "### Text Processing with CountVectorizer and TfidfVectorizer\nWe are going to be using CountVectorizer and TfidfVectorizer on the headlines to determine its influence on the target column."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "90878febb77aa9c2a14f420fedc3a8763e019e4e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ee95784fb1993f7f76453efc7714a23fb6e83f9a"
      },
      "cell_type": "markdown",
      "source": "### Clustering\nWe will be clustering the open and close features using KMeans."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "85c1e43b0e3d2b082a3e2badb0c13da2f3b0562c"
      },
      "cell_type": "code",
      "source": "def clustering(X):\n\n    def cluster_modelling(features):\n        df_set = X[features]\n        cluster_model = KMeans(n_clusters = 8)\n        cluster_model.fit(df_set)\n        return cluster_model.predict(df_set)\n    \n    # get columns:\n    vol_cols = [f for f in X.columns if f != 'volume' and 'volume' in f]\n    novelty_cols = [f for f in X.columns if 'novelty' in f]\n    \n    # fill nulls\n    cluster_cols = novelty_cols + vol_cols + ['open', 'close']\n    X[cluster_cols] = X[cluster_cols].fillna(0)\n    \n    X['cluster_open_close'] = cluster_modelling(['open', 'close'])\n    X['cluster_volume'] = cluster_modelling(vol_cols)\n    X['cluster_novelty'] = cluster_modelling(novelty_cols)\n    \n    return df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "84d6bbc9c805b3581afd36b49f80b583b1f9a5dc"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ab3199b41454b6093f0cd2be4dddf3b869824596"
      },
      "cell_type": "markdown",
      "source": "<a id='section3'></a>\n## Step 3. Modelling using Keras' Neural Network"
    },
    {
      "metadata": {
        "_uuid": "5853a3b60388bbab1fcd48a0d98d446d0f3d5826"
      },
      "cell_type": "markdown",
      "source": "### Preparing Datasets for Modelling\nWe will convert all the numerical and categorical datasets into rows that the neural network can process."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7230685136b783d05cd1069f3c680ec2120d6485"
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler\n\n# scale numerical columns\nscaler = StandardScaler()\n\nX_train = scaler.fit_transform(market_train_df[test_cols].fillna(0))\n\ny_train = market_train_df['returnsOpenNextMktres10']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4401ce84c431dc13bedb4e00b9b8f7d97145f7c3"
      },
      "cell_type": "code",
      "source": "def get_cols(X_train):\n    \n    # get numerical and categorical columns\n    num_cols = [f for f in X_train.columns if X_train[f].dtype == 'int' or X_train[f].dtype == 'float' and f not in ['universe', 'returnsOpenNextMktres10']]\n    cat_cols = [f for f in X_train.columns if f not in num_cols and f not in ['universe', 'returnsOpenNextMktres10']]\n    \n    return num_cols, cat_cols",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "76abdc01a2846fe429c2364a2a21cecae3e92fc0"
      },
      "cell_type": "markdown",
      "source": "### Fixed Training Split\nThe reason why we need to do a fixed training test split that fetches the last few rows of the training dataset is to avoid odd results, since randomly choosing rows will cause the validation dataset to be filled with rows with different timestamps."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96cba104e412b54f84ec6f348c633df92577c90c"
      },
      "cell_type": "code",
      "source": "def fixed_train_test_split(X, y, train_size):\n    \n    # round train size\n    train_size = int(train_size * len(X))\n    \n    # split data\n    X_train, y_train = X[train_size:], y[train_size:]\n    X_valid, y_valid = X[:train_size], y[:train_size]\n    \n    return X_train, y_train, X_valid, y_valid",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f554061d572cb8f8fd06cef48c3ef633e9db17d0"
      },
      "cell_type": "code",
      "source": "X_train, y_train, X_valid, y_valid = fixed_train_test_split(X_train, y_train, 5000)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "77a9aa17efdcf7cdad38590f92691b6e09761d67"
      },
      "cell_type": "code",
      "source": "# original from https://www.kaggle.com/christofhenkel/market-data-nn-baseline\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Embedding, Concatenate, Flatten, BatchNormalization\nfrom keras.losses import binary_crossentropy\n\n# categorical data\ncategorical_inputs = []\nfor cat in cat_cols:\n    categorical_inputs.append(Input(shape=[1], name=cat))\n\ncategorical_embeddings = []\nfor i, cat in enumerate(cat_cols):\n    categorical_embeddings.append(Embedding(embed_sizes[i], 10)(categorical_inputs[i]))\n    \ncategorical_logits = Flatten()(categorical_embeddings[0])\ncategorical_logits = Dense(32,activation='relu')(categorical_logits)\n\n# numerical data\nnumerical_inputs = Input(shape=(11,), name='num')\nnumerical_logits = numerical_inputs\nnumerical_logits = BatchNormalization()(numerical_logits)\n\nnumerical_logits = Dense(128,activation='relu')(numerical_logits)\nnumerical_logits = Dense(64,activation='relu')(numerical_logits)\n\n# combined\nlogits = Concatenate()([numerical_logits,categorical_logits])\nlogits = Dense(128,activation='relu')(logits)\nlogits = Dense(64,activation='relu')(logits)\nout = Dense(1, activation='sigmoid')(logits)\n\nmodel = Model(inputs = categorical_inputs + [numerical_inputs], outputs=out)\nmodel.compile(optimizer='adam',loss=binary_crossentropy)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dd66639fbbfdeb0a3f0fffd349bf0ea523c1edfa"
      },
      "cell_type": "code",
      "source": "get_cols(market_train_df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4c8dad53c38c7c24c88ec93d7ce8cf0c06807ad3"
      },
      "cell_type": "code",
      "source": "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n\n# set cylical learning rate per epoch\nlearning_rate = 1e-4\ndynamic_lr = LearningRateScheduler(lambda epoch: learning_rate * 0.99 ** epoch)\n\n# set early stopping\nearly_stop = EarlyStopping(patience=3)\n\nmodel.fit(X_train,y_train.astype(int),\n          validation_data=(X_valid,y_valid.astype(int)),\n          epochs=200,\n          verbose=0,\n         callbacks=[dynamic_lr, early_stop]) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c4c3c68f4745f6dc58181e8bc8e5a552d2385677"
      },
      "cell_type": "code",
      "source": "model.predict(X_valid)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "36a59163f089651745eaf40bb6250261a23aab24"
      },
      "cell_type": "markdown",
      "source": "<a id='section4'></a>\n## Step 4. Applying the Model\n"
    },
    {
      "metadata": {
        "_uuid": "cbcb1733a22212e40026b5bafdbb982b667446d6"
      },
      "cell_type": "markdown",
      "source": "**Sources:**\n* [Market Data NN Baseline by Christofhenkel](https://www.kaggle.com/christofhenkel/market-data-nn-baseline)\n* [a simple model using the market and news data by Bguberfain](https://www.kaggle.com/bguberfain/a-simple-model-using-the-market-and-news-data)\n* [Amateur Hour - Using Headlines to Predict Stocks by Magichanics](https://www.kaggle.com/magichanics/amateur-hour-using-headlines-to-predict-stocks)\n* [Simple Quant Features by Youhanlee](https://www.kaggle.com/youhanlee/simple-quant-features-using-python)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}